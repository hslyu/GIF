{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "caff5365",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6cbc5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch import nn\n",
    "\n",
    "from dataloader import mnist\n",
    "from models import ResNet18\n",
    "from src import freeze_influence, hessians, selection\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "target_removal_label = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4643ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_net(net, path):\n",
    "    assert os.path.isfile(path), \"Error: no checkpoint file found!\"\n",
    "    checkpoint = torch.load(path)\n",
    "    net.load_state_dict(checkpoint[\"net\"])\n",
    "    return net\n",
    "\n",
    "\n",
    "def save_net(net, path):\n",
    "    dir, filename = os.path.split(path)\n",
    "    if not os.path.isdir(dir):\n",
    "        os.makedirs(dir)\n",
    "\n",
    "    state = {\n",
    "        \"net\": net.state_dict(),\n",
    "    }\n",
    "    torch.save(state, path)\n",
    "\n",
    "\n",
    "def test(net, dataloader, criterion, label, include):\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        net_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        num_data = 0\n",
    "        for _, (inputs, targets) in enumerate(dataloader):\n",
    "            if include:\n",
    "                idx = targets == label\n",
    "            else:\n",
    "                idx = targets != label\n",
    "            inputs = inputs[idx]\n",
    "            targets = targets[idx]\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            net_loss += loss * len(inputs)\n",
    "            num_data +=  len(inputs)\n",
    "\n",
    "            total += targets.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        accuracy = correct / total * 100\n",
    "        net_loss /= num_data\n",
    "        return net_loss, accuracy\n",
    "\n",
    "def influence_test(net, dataloader, criterion, target_label):\n",
    "    def sample_test(net, criterion, inputs, targets):\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct = predicted.eq(targets).sum().item()\n",
    "\n",
    "            return loss, correct\n",
    "\n",
    "    self_loss = 0\n",
    "    self_correct = 0\n",
    "    num_self_inputs = 0\n",
    "    \n",
    "    exclusive_loss = 0\n",
    "    exclusive_correct = 0\n",
    "    num_exclusive_inputs = 0\n",
    "    \n",
    "    for _, (inputs, targets) in enumerate(dataloader):\n",
    "        target_idx = (targets == target_label)\n",
    "        batch_self_loss, batch_self_correct = sample_test(net, criterion, inputs[target_idx], targets[target_idx])\n",
    "        batch_exclusive_loss, batch_exclusive_correct = sample_test(net, criterion, inputs[~target_idx], targets[~target_idx])\n",
    "        \n",
    "        len_self_batch = len(inputs[target_idx])\n",
    "        self_loss += batch_self_loss * len_self_batch\n",
    "        self_correct += batch_self_correct\n",
    "        num_self_inputs += len_self_batch\n",
    "        \n",
    "        len_exclusive_batch = len(inputs[~target_idx])\n",
    "        exclusive_loss += batch_exclusive_loss * len_exclusive_batch\n",
    "        exclusive_correct += batch_exclusive_correct\n",
    "        num_exclusive_inputs += len_exclusive_batch\n",
    "        \n",
    "    self_loss /= num_self_inputs\n",
    "    self_acc = self_correct / num_self_inputs * 100\n",
    "    exclusive_loss /= num_exclusive_inputs\n",
    "    exclusive_acc = exclusive_correct / num_exclusive_inputs * 100\n",
    "    \n",
    "    return self_loss, self_acc, exclusive_loss, exclusive_acc\n",
    "\n",
    "def projected_influence(net, total_loss, target_loss, index_list, tol, step, max_iter, verbose):\n",
    "    num_param = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "    full_param_index_list = np.arange(num_param)\n",
    "    influence = hessians.generalized_influence(\n",
    "        net, total_loss, target_loss, full_param_index_list, tol=tol, step=step, max_iter=max_iter, verbose=verbose\n",
    "    )\n",
    "    return influence[idx]\n",
    "\n",
    "def f1_score(self_acc, test_acc):\n",
    "    self_acc /= 100\n",
    "    test_acc /= 100\n",
    "    if self_acc == 1 and test_acc == 0:\n",
    "        return 0\n",
    "    return 2 * (1 - self_acc) * test_acc / (1 - self_acc + test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d193c3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Building ResNet18 finished. \n",
      "    Number of parameters: 11172810\n",
      "==> Preparing data..\n",
      "Original loss and acc : 0.0303, 99.09%\n"
     ]
    }
   ],
   "source": [
    "net = ResNet18(1).to(device)\n",
    "net_name = \"ResNet18\"\n",
    "\n",
    "if device == \"cuda\":\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "net_path = f\"checkpoints/tab2/{net_name}/cross_entropy/ckpt_0.0.pth\"\n",
    "net = load_net(net, net_path)\n",
    "\n",
    "net.eval()\n",
    "num_param = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "print(\n",
    "    f\"==> Building {net_name} finished. \"\n",
    "    + f\"\\n    Number of parameters: {num_param}\"\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Data\n",
    "print(\"==> Preparing data..\")\n",
    "batch_size = 512\n",
    "num_workers = 16\n",
    "num_sample_batch = 1\n",
    "num_target_sample = 512\n",
    "\n",
    "data_loader = mnist.MNISTDataLoader(batch_size, num_workers, validation=False)\n",
    "train_loader, test_loader = data_loader.get_data_loaders()\n",
    "\n",
    "loss, acc = test(net, test_loader, criterion, 11, False)\n",
    "print(\n",
    "    f\"Original loss and acc : {loss:.4f}, {acc:.2f}%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ede70d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = True\n",
    "num_exp = 10\n",
    "\n",
    "removal_inputs = list()\n",
    "removal_targets = list()\n",
    "for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "    idx = targets == target_removal_label\n",
    "    removal_inputs.append(inputs[idx])\n",
    "    removal_targets.append(targets[idx])\n",
    "removal_inputs = torch.cat(removal_inputs)\n",
    "removal_targets = torch.cat(removal_targets)\n",
    "\n",
    "ratio_list = [.1, .3, .5]\n",
    "result_list_TopNActivations = []\n",
    "result_list_TopNGradients = []\n",
    "result_list_Random = []\n",
    "result_list_Threshold = []\n",
    "tol = 1e-9\n",
    "\n",
    "parser_list = [selection.TopNActivations,\n",
    "              selection.TopNGradients,\n",
    "              selection.Random,\n",
    "              selection.Threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2e343f0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TopNActivations - ratio: 10.0%\n",
      "test acc: 97.94, test loss: 0.0697 | self-acc: 0.00%, self loss: 3.5648 | Score: 0.9895822                    \n",
      "TopNGradients - ratio: 10.0%\n",
      "test acc: 98.54, test loss: 0.0493 | self-acc: 0.00%, self loss: 3.8372 | Score: 0.9926290                    \n",
      "Random - ratio: 10.0%\n",
      "test acc: 93.29, test loss: 0.2194 | self-acc: 0.71%, self loss: 4.3436 | Score: 0.9619595                    \n",
      "Threshold - ratio: 10.0%\n",
      "test acc: 94.79, test loss: 0.1868 | self-acc: 0.20%, self loss: 4.2027 | Score: 0.9722823                    \n",
      "\n",
      "TopNActivations - ratio: 30.0%\n",
      "test acc: 93.82, test loss: 0.2264 | self-acc: 0.82%, self loss: 4.1612 | Score: 0.9642986                    \n",
      "TopNGradients - ratio: 30.0%\n",
      "test acc: 97.37, test loss: 0.0920 | self-acc: 0.20%, self loss: 4.6977 | Score: 0.9856932                    \n",
      "Random - ratio: 30.0%\n",
      "test acc: 92.11, test loss: 0.2850 | self-acc: 2.14%, self loss: 3.6935 | Score: 0.9489474                    \n",
      "Threshold - ratio: 30.0%\n",
      "test acc: 94.47, test loss: 0.1920 | self-acc: 1.22%, self loss: 4.1492 | Score: 0.9657367                    \n",
      "\n",
      "TopNActivations - ratio: 50.0%\n",
      "test acc: 93.99, test loss: 0.2151 | self-acc: 1.22%, self loss: 3.9629 | Score: 0.9632395                    \n",
      "TopNGradients - ratio: 50.0%\n",
      "test acc: 95.07, test loss: 0.1724 | self-acc: 0.82%, self loss: 4.6251 | Score: 0.9708146                    \n",
      "Random - ratio: 50.0%\n",
      "test acc: 92.56, test loss: 0.2581 | self-acc: 0.82%, self loss: 4.2088 | Score: 0.9575795                    \n",
      "Threshold - ratio: 50.0%\n",
      "test acc: 91.03, test loss: 0.3061 | self-acc: 2.86%, self loss: 3.8884 | Score: 0.9398769                    \n",
      "\n",
      "TopNActivations - ratio: 10.0%\n",
      "test acc: 97.33, test loss: 0.0924 | self-acc: 0.00%, self loss: 3.5630 | Score: 0.9864599                    \n",
      "TopNGradients - ratio: 10.0%\n",
      "test acc: 97.01, test loss: 0.1001 | self-acc: 0.31%, self loss: 3.9171 | Score: 0.9833191                    \n",
      "Random - ratio: 10.0%\n",
      "test acc: 91.20, test loss: 0.2859 | self-acc: 1.33%, self loss: 4.0365 | Score: 0.9478822                    \n",
      "Threshold - ratio: 10.0%\n",
      "test acc: 90.81, test loss: 0.3100 | self-acc: 2.35%, self loss: 3.8116 | Score: 0.9410693                    \n",
      "\n",
      "TopNActivations - ratio: 30.0%\n",
      "test acc: 93.69, test loss: 0.2144 | self-acc: 0.31%, self loss: 4.1430 | Score: 0.9659969                    \n",
      "TopNGradients - ratio: 30.0%\n",
      "test acc: 96.77, test loss: 0.1140 | self-acc: 0.41%, self loss: 4.4574 | Score: 0.9816262                    \n",
      "Random - ratio: 30.0%\n",
      "test acc: 91.09, test loss: 0.3025 | self-acc: 0.92%, self loss: 4.2420 | Score: 0.9491599                    \n",
      "Threshold - ratio: 30.0%\n",
      "test acc: 91.11, test loss: 0.3030 | self-acc: 0.41%, self loss: 4.4585 | Score: 0.9516156                    \n",
      "\n",
      "TopNActivations - ratio: 50.0%\n",
      "test acc: 92.82, test loss: 0.2462 | self-acc: 0.51%, self loss: 4.5037 | Score: 0.9603707                    \n",
      "TopNGradients - ratio: 50.0%\n",
      "test acc: 94.98, test loss: 0.1638 | self-acc: 0.10%, self loss: 4.6743 | Score: 0.9737578                    \n",
      "Random - ratio: 50.0%\n",
      "test acc: 90.17, test loss: 0.3212 | self-acc: 1.84%, self loss: 3.9384 | Score: 0.9399500                    \n",
      "Threshold - ratio: 50.0%\n",
      "test acc: 93.80, test loss: 0.2171 | self-acc: 0.31%, self loss: 4.3847 | Score: 0.9665859                    \n",
      "\n",
      "TopNActivations - ratio: 10.0%\n",
      "test acc: 96.93, test loss: 0.1104 | self-acc: 0.31%, self loss: 3.2601 | Score: 0.9829202                    \n",
      "TopNGradients - ratio: 10.0%\n",
      "test acc: 97.62, test loss: 0.0811 | self-acc: 0.00%, self loss: 4.3424 | Score: 0.9879383                    \n",
      "Random - ratio: 10.0%\n",
      "test acc: 93.17, test loss: 0.2287 | self-acc: 0.92%, self loss: 3.9164 | Score: 0.9603532                    \n",
      "Threshold - ratio: 10.0%\n",
      "test acc: 90.68, test loss: 0.3029 | self-acc: 2.86%, self loss: 3.7784 | Score: 0.9379824                    \n",
      "\n",
      "TopNActivations - ratio: 30.0%\n",
      "test acc: 92.83, test loss: 0.2520 | self-acc: 1.12%, self loss: 3.9738 | Score: 0.9575682                    \n",
      "TopNGradients - ratio: 30.0%\n",
      "test acc: 96.82, test loss: 0.1058 | self-acc: 0.31%, self loss: 3.9914 | Score: 0.9823499                    \n",
      "Random - ratio: 30.0%\n",
      "test acc: 83.84, test loss: 0.5120 | self-acc: 3.88%, self loss: 3.7125 | Score: 0.8955976                    \n",
      "Threshold - ratio: 30.0%\n",
      "test acc: 93.23, test loss: 0.2272 | self-acc: 2.76%, self loss: 3.5930 | Score: 0.9519314                    \n",
      "\n",
      "TopNActivations - ratio: 50.0%\n",
      "test acc: 87.51, test loss: 0.3976 | self-acc: 2.35%, self loss: 4.1935 | Score: 0.9230124                    \n",
      "TopNGradients - ratio: 50.0%\n",
      "test acc: 94.91, test loss: 0.1745 | self-acc: 0.00%, self loss: 4.6644 | Score: 0.9738923                    \n",
      "Random - ratio: 50.0%\n",
      "test acc: 91.82, test loss: 0.2734 | self-acc: 1.63%, self loss: 4.0894 | Score: 0.9498000                    \n",
      "Threshold - ratio: 50.0%\n",
      "test acc: 92.80, test loss: 0.2476 | self-acc: 0.61%, self loss: 4.3722 | Score: 0.9598358                    \n",
      "\n",
      "TopNActivations - ratio: 10.0%\n",
      "test acc: 96.67, test loss: 0.1135 | self-acc: 0.00%, self loss: 3.5795 | Score: 0.9830891                    \n",
      "TopNGradients - ratio: 10.0%\n",
      "test acc: 97.65, test loss: 0.0817 | self-acc: 0.10%, self loss: 4.1185 | Score: 0.9876102                    \n",
      "Random - ratio: 10.0%\n",
      "test acc: 90.10, test loss: 0.3241 | self-acc: 1.84%, self loss: 3.9122 | Score: 0.9395884                    \n",
      "Threshold - ratio: 10.0%\n",
      "test acc: 89.45, test loss: 0.3484 | self-acc: 0.31%, self loss: 4.5349 | Score: 0.9429214                    \n",
      "\n",
      "TopNActivations - ratio: 30.0%\n",
      "test acc: 96.16, test loss: 0.1310 | self-acc: 0.41%, self loss: 4.0724 | Score: 0.9784795                    \n",
      "TopNGradients - ratio: 30.0%\n",
      "test acc: 97.00, test loss: 0.1020 | self-acc: 0.41%, self loss: 4.5434 | Score: 0.9827656                    \n",
      "Random - ratio: 30.0%\n",
      "test acc: 90.94, test loss: 0.2912 | self-acc: 2.45%, self loss: 3.8405 | Score: 0.9413083                    \n",
      "Threshold - ratio: 30.0%\n",
      "test acc: 89.56, test loss: 0.3623 | self-acc: 2.45%, self loss: 3.7727 | Score: 0.9338299                    \n",
      "\n",
      "TopNActivations - ratio: 50.0%\n",
      "test acc: 92.86, test loss: 0.2600 | self-acc: 1.02%, self loss: 4.1345 | Score: 0.9582236                    \n",
      "TopNGradients - ratio: 50.0%\n",
      "test acc: 95.13, test loss: 0.1672 | self-acc: 0.41%, self loss: 4.6040 | Score: 0.9731139                    \n",
      "Random - ratio: 50.0%\n",
      "test acc: 89.50, test loss: 0.3445 | self-acc: 0.92%, self loss: 3.9547 | Score: 0.9404801                    \n",
      "Threshold - ratio: 50.0%\n",
      "test acc: 91.93, test loss: 0.2745 | self-acc: 1.84%, self loss: 3.8512 | Score: 0.9494393                    \n",
      "\n",
      "TopNActivations - ratio: 10.0%\n",
      "test acc: 94.31, test loss: 0.2025 | self-acc: 0.20%, self loss: 3.5502 | Score: 0.9697683                    \n",
      "TopNGradients - ratio: 10.0%\n",
      "test acc: 96.50, test loss: 0.1243 | self-acc: 0.20%, self loss: 4.5717 | Score: 0.9811857                    \n",
      "Random - ratio: 10.0%\n",
      "test acc: 78.77, test loss: 0.8612 | self-acc: 3.06%, self loss: 4.6784 | Score: 0.8691467                    \n",
      "Threshold - ratio: 10.0%\n",
      "test acc: 73.98, test loss: 1.1232 | self-acc: 6.22%, self loss: 4.9567 | Score: 0.8270983                    \n",
      "\n",
      "TopNActivations - ratio: 30.0%\n",
      "test acc: 89.73, test loss: 0.3665 | self-acc: 0.41%, self loss: 4.6474 | Score: 0.9440624                    \n",
      "TopNGradients - ratio: 30.0%\n",
      "test acc: 92.72, test loss: 0.2788 | self-acc: 0.20%, self loss: 5.1717 | Score: 0.9612587                    \n",
      "Random - ratio: 30.0%\n",
      "test acc: 90.84, test loss: 0.3251 | self-acc: 1.02%, self loss: 4.8819 | Score: 0.9473668                    \n",
      "Threshold - ratio: 30.0%\n",
      "test acc: 84.42, test loss: 0.5795 | self-acc: 1.02%, self loss: 5.0109 | Score: 0.9112391                    \n",
      "\n",
      "TopNActivations - ratio: 50.0%\n",
      "test acc: 78.14, test loss: 0.8737 | self-acc: 0.92%, self loss: 5.9027 | Score: 0.8737194                    \n",
      "TopNGradients - ratio: 50.0%\n",
      "test acc: 94.09, test loss: 0.2065 | self-acc: 0.20%, self loss: 4.7055 | Score: 0.9685948                    \n",
      "Random - ratio: 50.0%\n",
      "test acc: 81.26, test loss: 0.7715 | self-acc: 4.29%, self loss: 5.0080 | Score: 0.8789913                    \n",
      "Threshold - ratio: 50.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc: 71.94, test loss: 1.2057 | self-acc: 1.33%, self loss: 6.1965 | Score: 0.8321239                    \n",
      "\n",
      "TopNActivations - ratio: 10.0%\n",
      "test acc: 95.03, test loss: 0.1868 | self-acc: 0.00%, self loss: 3.6806 | Score: 0.9745339                    \n",
      "TopNGradients - ratio: 10.0%\n",
      "test acc: 98.12, test loss: 0.0674 | self-acc: 0.00%, self loss: 3.9974 | Score: 0.9904868                    \n",
      "Random - ratio: 10.0%\n",
      "test acc: 88.05, test loss: 0.4621 | self-acc: 1.53%, self loss: 5.0408 | Score: 0.9296799                    \n",
      "Threshold - ratio: 10.0%\n",
      "test acc: 84.82, test loss: 0.5502 | self-acc: 6.33%, self loss: 3.9136 | Score: 0.8902861                    \n",
      "\n",
      "TopNActivations - ratio: 30.0%\n",
      "test acc: 92.83, test loss: 0.2574 | self-acc: 0.20%, self loss: 4.4309 | Score: 0.9618542                    \n",
      "TopNGradients - ratio: 30.0%\n",
      "test acc: 96.40, test loss: 0.1290 | self-acc: 0.10%, self loss: 4.7946 | Score: 0.9811621                    \n",
      "Random - ratio: 30.0%\n",
      "test acc: 85.23, test loss: 0.5937 | self-acc: 3.06%, self loss: 4.9530 | Score: 0.9070970                    \n",
      "Threshold - ratio: 30.0%\n",
      "test acc: 86.64, test loss: 0.5152 | self-acc: 0.82%, self loss: 5.4246 | Score: 0.9248892                    \n",
      "\n",
      "TopNActivations - ratio: 50.0%\n",
      "test acc: 86.62, test loss: 0.5090 | self-acc: 4.08%, self loss: 4.7408 | Score: 0.9103160                    \n",
      "TopNGradients - ratio: 50.0%\n",
      "test acc: 96.88, test loss: 0.1147 | self-acc: 0.41%, self loss: 4.3867 | Score: 0.9821962                    \n",
      "Random - ratio: 50.0%\n",
      "test acc: 83.25, test loss: 0.6758 | self-acc: 2.76%, self loss: 4.6706 | Score: 0.8970393                    \n",
      "Threshold - ratio: 50.0%\n",
      "test acc: 91.21, test loss: 0.3121 | self-acc: 1.12%, self loss: 4.7855 | Score: 0.9488828                    \n",
      "\n",
      "TopNActivations - ratio: 10.0%\n",
      "test acc: 94.86, test loss: 0.1795 | self-acc: 0.00%, self loss: 3.4568 | Score: 0.9736004                    \n",
      "TopNGradients - ratio: 10.0%\n",
      "test acc: 97.74, test loss: 0.0760 | self-acc: 0.20%, self loss: 3.6234 | Score: 0.9875642                    \n",
      "Random - ratio: 10.0%\n",
      "test acc: 85.90, test loss: 0.4920 | self-acc: 1.94%, self loss: 4.1803 | Score: 0.9157750                    \n",
      "Threshold - ratio: 10.0%\n",
      "test acc: 89.09, test loss: 0.3889 | self-acc: 1.94%, self loss: 3.7507 | Score: 0.9336109                    \n",
      "\n",
      "TopNActivations - ratio: 30.0%\n",
      "test acc: 92.64, test loss: 0.2420 | self-acc: 0.41%, self loss: 4.0481 | Score: 0.9598945                    \n",
      "TopNGradients - ratio: 30.0%\n",
      "test acc: 97.94, test loss: 0.0725 | self-acc: 0.00%, self loss: 4.6064 | Score: 0.9895822                    \n",
      "Random - ratio: 30.0%\n",
      "test acc: 91.77, test loss: 0.2953 | self-acc: 1.43%, self loss: 4.4692 | Score: 0.9505125                    \n",
      "Threshold - ratio: 30.0%\n",
      "test acc: 92.85, test loss: 0.2412 | self-acc: 0.71%, self loss: 4.4286 | Score: 0.9595966                    \n",
      "\n",
      "TopNActivations - ratio: 50.0%\n",
      "test acc: 91.01, test loss: 0.2956 | self-acc: 1.33%, self loss: 3.9695 | Score: 0.9468632                    \n",
      "TopNGradients - ratio: 50.0%\n",
      "test acc: 94.78, test loss: 0.1769 | self-acc: 0.92%, self loss: 4.2322 | Score: 0.9688219                    \n",
      "Random - ratio: 50.0%\n",
      "test acc: 91.81, test loss: 0.2958 | self-acc: 1.33%, self loss: 4.2063 | Score: 0.9511652                    \n",
      "Threshold - ratio: 50.0%\n",
      "test acc: 90.20, test loss: 0.3313 | self-acc: 0.82%, self loss: 4.1242 | Score: 0.9447852                    \n",
      "\n",
      "TopNActivations - ratio: 10.0%\n",
      "test acc: 96.97, test loss: 0.1074 | self-acc: 0.00%, self loss: 3.4386 | Score: 0.9846344                    \n",
      "TopNGradients - ratio: 10.0%\n",
      "test acc: 98.65, test loss: 0.0466 | self-acc: 0.00%, self loss: 3.9159 | Score: 0.9931912                    \n",
      "Random - ratio: 10.0%\n",
      "test acc: 94.41, test loss: 0.1978 | self-acc: 0.10%, self loss: 4.6628 | Score: 0.9707776                    \n",
      "Threshold - ratio: 10.0%\n",
      "test acc: 91.71, test loss: 0.3096 | self-acc: 1.53%, self loss: 4.2385 | Score: 0.9496813                    \n",
      "\n",
      "TopNActivations - ratio: 30.0%\n",
      "test acc: 93.90, test loss: 0.2112 | self-acc: 0.51%, self loss: 3.9583 | Score: 0.9661540                    \n",
      "TopNGradients - ratio: 30.0%\n",
      "test acc: 97.88, test loss: 0.0695 | self-acc: 0.00%, self loss: 4.7139 | Score: 0.9892991                    \n",
      "Random - ratio: 30.0%\n",
      "test acc: 94.29, test loss: 0.2013 | self-acc: 0.92%, self loss: 4.5146 | Score: 0.9662669                    \n",
      "Threshold - ratio: 30.0%\n",
      "test acc: 93.09, test loss: 0.2354 | self-acc: 0.82%, self loss: 4.1717 | Score: 0.9604194                    \n",
      "\n",
      "TopNActivations - ratio: 50.0%\n",
      "test acc: 95.20, test loss: 0.1725 | self-acc: 1.02%, self loss: 4.1706 | Score: 0.9705278                    \n",
      "TopNGradients - ratio: 50.0%\n",
      "test acc: 97.22, test loss: 0.0953 | self-acc: 0.20%, self loss: 4.3257 | Score: 0.9848973                    \n",
      "Random - ratio: 50.0%\n",
      "test acc: 95.35, test loss: 0.1670 | self-acc: 0.82%, self loss: 3.7574 | Score: 0.9723154                    \n",
      "Threshold - ratio: 50.0%\n",
      "test acc: 95.22, test loss: 0.1642 | self-acc: 0.00%, self loss: 4.6428 | Score: 0.9755239                    \n",
      "\n",
      "TopNActivations - ratio: 10.0%\n",
      "test acc: 94.57, test loss: 0.1757 | self-acc: 0.31%, self loss: 3.3215 | Score: 0.9706312                    \n",
      "TopNGradients - ratio: 10.0%\n",
      "test acc: 97.07, test loss: 0.0947 | self-acc: 0.00%, self loss: 4.5330 | Score: 0.9851485                    \n",
      "Random - ratio: 10.0%\n",
      "test acc: 92.89, test loss: 0.2402 | self-acc: 1.22%, self loss: 3.9707 | Score: 0.9574429                    \n",
      "Threshold - ratio: 10.0%\n",
      "test acc: 92.05, test loss: 0.2701 | self-acc: 0.51%, self loss: 4.2884 | Score: 0.9562595                    \n",
      "\n",
      "TopNActivations - ratio: 30.0%\n",
      "test acc: 94.82, test loss: 0.1831 | self-acc: 0.61%, self loss: 4.0193 | Score: 0.9705153                    \n",
      "TopNGradients - ratio: 30.0%\n",
      "test acc: 96.04, test loss: 0.1348 | self-acc: 0.92%, self loss: 4.0090 | Score: 0.9753821                    \n",
      "Random - ratio: 30.0%\n",
      "test acc: 85.69, test loss: 0.4794 | self-acc: 5.10%, self loss: 3.4031 | Score: 0.9005777                    \n",
      "Threshold - ratio: 30.0%\n",
      "test acc: 89.12, test loss: 0.3587 | self-acc: 4.49%, self loss: 3.4022 | Score: 0.9220675                    \n",
      "\n",
      "TopNActivations - ratio: 50.0%\n",
      "test acc: 89.97, test loss: 0.3587 | self-acc: 2.35%, self loss: 3.5018 | Score: 0.9365246                    \n",
      "TopNGradients - ratio: 50.0%\n",
      "test acc: 93.26, test loss: 0.2295 | self-acc: 1.43%, self loss: 4.3955 | Score: 0.9584188                    \n",
      "Random - ratio: 50.0%\n",
      "test acc: 83.36, test loss: 0.5359 | self-acc: 5.00%, self loss: 3.7118 | Score: 0.8879973                    \n",
      "Threshold - ratio: 50.0%\n",
      "test acc: 90.61, test loss: 0.3075 | self-acc: 1.73%, self loss: 4.1114 | Score: 0.9428238                    \n",
      "\n",
      "TopNActivations - ratio: 10.0%\n",
      "test acc: 93.48, test loss: 0.2468 | self-acc: 0.71%, self loss: 3.4898 | Score: 0.9629604                    \n",
      "TopNGradients - ratio: 10.0%\n",
      "test acc: 97.66, test loss: 0.0845 | self-acc: 0.10%, self loss: 4.2001 | Score: 0.9876669                    \n",
      "Random - ratio: 10.0%\n",
      "test acc: 90.03, test loss: 0.3678 | self-acc: 2.24%, self loss: 4.2980 | Score: 0.9373542                    \n",
      "Threshold - ratio: 10.0%\n",
      "test acc: 90.02, test loss: 0.3838 | self-acc: 0.61%, self loss: 5.0344 | Score: 0.9447342                    \n",
      "\n",
      "TopNActivations - ratio: 30.0%\n",
      "test acc: 87.55, test loss: 0.4550 | self-acc: 1.02%, self loss: 4.8458 | Score: 0.9291456                    \n",
      "TopNGradients - ratio: 30.0%\n",
      "test acc: 97.82, test loss: 0.0752 | self-acc: 0.00%, self loss: 4.5338 | Score: 0.9889593                    \n",
      "Random - ratio: 30.0%\n",
      "test acc: 83.88, test loss: 0.6330 | self-acc: 2.24%, self loss: 5.0278 | Score: 0.9028775                    \n",
      "Threshold - ratio: 30.0%\n",
      "test acc: 85.76, test loss: 0.5300 | self-acc: 2.04%, self loss: 4.6857 | Score: 0.9145740                    \n",
      "\n",
      "TopNActivations - ratio: 50.0%\n",
      "test acc: 86.52, test loss: 0.5059 | self-acc: 2.24%, self loss: 4.6429 | Score: 0.9179440                    \n",
      "TopNGradients - ratio: 50.0%\n",
      "test acc: 94.17, test loss: 0.2219 | self-acc: 0.00%, self loss: 5.2715 | Score: 0.9699669                    \n",
      "Random - ratio: 50.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc: 89.18, test loss: 0.3919 | self-acc: 0.71%, self loss: 4.2386 | Score: 0.9396170                    \n",
      "Threshold - ratio: 50.0%\n",
      "test acc: 90.11, test loss: 0.3718 | self-acc: 2.45%, self loss: 4.7046 | Score: 0.9368345                    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_exp):\n",
    "    sample_idx = np.random.choice(len(removal_inputs), num_target_sample, replace=False)\n",
    "    for param_ratio in ratio_list:\n",
    "        for parser in parser_list:\n",
    "\n",
    "            print(f\"{parser.__name__} - ratio: {param_ratio*100}%\")\n",
    "            # Initialize network\n",
    "            net = load_net(net, net_path)\n",
    "\n",
    "            # Compute total loss\n",
    "            total_loss = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "                if batch_idx >= num_sample_batch:\n",
    "                    break\n",
    "                idx = targets != target_removal_label\n",
    "                inputs, targets = inputs[idx], targets[idx]\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = net(inputs)\n",
    "                total_loss += criterion(outputs, targets)\n",
    "\n",
    "            # Sampling the target removal data\n",
    "            sample_removal_inputs = removal_inputs[sample_idx]\n",
    "            sample_removal_targets = removal_targets[sample_idx]\n",
    "            \n",
    "            # Make hooks\n",
    "            net_parser = parser(net, param_ratio)\n",
    "            net_parser.register_hooks()\n",
    "\n",
    "            if isinstance(net_parser, selection.TopNGradients):\n",
    "                # Compute target loss\n",
    "                target_loss = (\n",
    "                    criterion(net(sample_removal_inputs.to(device)), sample_removal_targets.to(device))\n",
    "                    * len(removal_inputs)\n",
    "                    / (len(train_loader.dataset) - len(removal_inputs))\n",
    "                )\n",
    "                target_loss.backward()\n",
    "                net_parser.remove_hooks()\n",
    "\n",
    "            target_loss = (\n",
    "                criterion(net(sample_removal_inputs.to(device)), sample_removal_targets.to(device))\n",
    "                * len(removal_inputs)\n",
    "                / (len(train_loader.dataset) - len(removal_inputs))\n",
    "            )\n",
    "            \n",
    "            # Delete hooks\n",
    "            index_list = net_parser.get_parameters()\n",
    "            net_parser.remove_hooks()\n",
    "            \n",
    "            influence = hessians.generalized_influence(\n",
    "                net, total_loss, target_loss, index_list, tol=tol, step=3, max_iter=30, verbose=False\n",
    "            )\n",
    "            del target_loss, total_loss\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            influence = influence * 0.05 / torch.norm(influence)\n",
    "                \n",
    "            scale = 1\n",
    "            score = 0\n",
    "            best_score = -1\n",
    "            count = 1\n",
    "            save_path = (\n",
    "                f\"checkpoints/tab1/{net_name}/{net_parser.__class__.__name__}/{param_ratio}_{i}.pth\"\n",
    "            )\n",
    "            while True:\n",
    "                if score < .85:\n",
    "                    net_parser.update_network(influence * scale)\n",
    "                else:\n",
    "                    net_parser.update_network(influence * scale / 3)\n",
    "\n",
    "#                 self_loss, self_acc = test(net, test_loader, criterion, target_removal_label, True)\n",
    "#                 exclusive_loss, exclusive_acc = test(net, test_loader, criterion, target_removal_label, False)\n",
    "                self_loss, self_acc, exclusive_loss, exclusive_acc = influence_test(net, test_loader, \n",
    "                                                                                    criterion, target_removal_label)\n",
    "                score = f1_score(self_acc, exclusive_acc)\n",
    "                \n",
    "                if best_score < score:\n",
    "                    best_result = [exclusive_acc, exclusive_loss, self_acc, self_loss, score]\n",
    "                    best_score = score\n",
    "                    save_net(net, save_path)\n",
    "                    \n",
    "                if verbose:\n",
    "                    print(\n",
    "                    f\"{count} - test acc: {exclusive_acc:2.2f}, test loss: {exclusive_loss:.4f} |\" +\n",
    "                    f\" self-acc: {self_acc:2.2f}%, self loss: {self_loss:.4f} | score: {score:.7f}\",\n",
    "                    end='\\r'\n",
    "                    )\n",
    "                \n",
    "                if exclusive_acc < 80 or self_acc < 0.01 or count >= 200:\n",
    "                    if i == 0:\n",
    "                        result_list_TopNActivations += best_result\n",
    "                    elif i == 1:\n",
    "                        result_list_TopNGradients += best_result\n",
    "                    elif i == 2:\n",
    "                        result_list_Random += best_result\n",
    "                    else:\n",
    "                        result_list_Threshold += best_result\n",
    "                    \n",
    "                    print(f\"test acc: {best_result[0]:2.2f}, test loss: {best_result[1]:.4f} | \" +\n",
    "                          f\"self-acc: {best_result[2]:2.2f}%, self loss: {best_result[3]:.4f} | \" +\n",
    "                          f\"Score: {best_result[4]:.7f}\" + \" \" * 20) \n",
    "                    break\n",
    "                elif count >= 20 and best_score < 0.2:\n",
    "                    scale *= 5\n",
    "                elif count >= 50 and best_score < 0.5:\n",
    "                    print(f\"test acc: {best_result[0]:2.2f}, test loss: {best_result[1]:.4f} | \" +\n",
    "                          f\"self-acc: {best_result[2]:2.2f}%, self loss: {best_result[3]:.4f} | \" +\n",
    "                          f\"Score: {best_result[4]:.7f}\" + \" \" * 20) \n",
    "                    break\n",
    "\n",
    "                count += 1\n",
    "                \n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3db0d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TopNActivations - ratio: 10.0%\n",
      "  test acc: 93.78, test loss: 0.2367 | self-acc: 1.12%, self loss: 3.4874\r"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'f1_score_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 35\u001b[0m\n\u001b[1;32m     33\u001b[0m mean_exclusive_loss \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(exclusive_loss_list)\n\u001b[1;32m     34\u001b[0m mean_exclusive_acc \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(exclusive_acc_list)\n\u001b[0;32m---> 35\u001b[0m mean_f1_score \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(\u001b[43mf1_score_list\u001b[49m)\n\u001b[1;32m     37\u001b[0m var_self_loss \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvar(self_loss_list)\n\u001b[1;32m     38\u001b[0m var_self_acc \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvar(self_acc_list)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'f1_score_list' is not defined"
     ]
    }
   ],
   "source": [
    "for param_ratio in ratio_list:\n",
    "    print(\"\")\n",
    "    for parser in parser_list:\n",
    "        print(f\"{parser.__name__} - ratio: {param_ratio*100}%\")\n",
    "        \n",
    "        self_loss_list = np.empty(0)\n",
    "        self_acc_list = np.empty(0)\n",
    "        exclusive_loss_list = np.empty(0)\n",
    "        exclusive_acc_list = np.empty(0)\n",
    "        \n",
    "        for i in range(num_exp):\n",
    "\n",
    "            load_path = (\n",
    "                f\"checkpoints/tab1/{net_name}/{parser.__name__}/{param_ratio}_{i}.pth\"\n",
    "            )\n",
    "            net = ResNet18(1).to(device)\n",
    "            net = load_net(net, load_path)\n",
    "            self_loss, self_acc, exclusive_loss, exclusive_acc = influence_test(net, test_loader, \n",
    "                                                                    criterion, target_removal_label)\n",
    "            \n",
    "            self_loss_list = np.append(self_loss_list, self_loss.detach().cpu().numpy())\n",
    "            self_acc_list = np.append(self_acc_list, self_acc)\n",
    "            exclusive_loss_list = np.append(exclusive_loss_list, exclusive_loss.detach().cpu().numpy())\n",
    "            exclusive_acc_list = np.append(exclusive_acc_list, exclusive_acc)\n",
    "            print(\n",
    "            f\"  test acc: {exclusive_acc:2.2f}, test loss: {exclusive_loss:.4f} | \" +\n",
    "            f\"self-acc: {self_acc:2.2f}%, self loss: {self_loss:.4f}\",\n",
    "            end='\\r'\n",
    "            )\n",
    "            \n",
    "        mean_self_loss = np.mean(self_loss_list)\n",
    "        mean_self_acc = np.mean(self_acc_list)\n",
    "        mean_exclusive_loss = np.mean(exclusive_loss_list)\n",
    "        mean_exclusive_acc = np.mean(exclusive_acc_list)\n",
    "        mean_f1_score = np.mean(f1_score_list)\n",
    "                \n",
    "        var_self_loss = np.var(self_loss_list)\n",
    "        var_self_acc = np.var(self_acc_list)\n",
    "        var_exclusive_loss = np.var(exclusive_loss_list)\n",
    "        var_exclusive_acc = np.var(exclusive_acc_list)\n",
    "        var_f1_score = np.var(f1_score_list)\n",
    "\n",
    "        print(\n",
    "        f\"{mean_exclusive_acc:2.2f} $\\pm$ {var_exclusive_acc:2.2f} & \" +\n",
    "        f\"{mean_exclusive_loss:.4f} $\\pm$ {var_exclusive_loss:.4f} & \", end=\"\"\n",
    "        )\n",
    "        print(\n",
    "        f\"{mean_self_acc:2.2f} $\\pm$ {var_self_acc:2.2f} & \" +\n",
    "        f\"{mean_self_loss:.4f} $\\pm$ {var_self_loss:.4f} \"\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

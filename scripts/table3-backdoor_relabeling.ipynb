{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa27286d-8daf-4537-abac-3f4f066888e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c29c6ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "\n",
    "from dataloader import mnist\n",
    "from models import FullyConnectedNet, TinyNet, ResNet18\n",
    "from src import utils, selection, hessians, freeze_influence, second_influence\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "flatten = False\n",
    "label = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e86bcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_net(net, path):\n",
    "    assert os.path.isfile(path), \"Error: no checkpoint file found!\"\n",
    "    checkpoint = torch.load(path)\n",
    "    net.load_state_dict(checkpoint[\"net\"])\n",
    "    return net\n",
    "\n",
    "\n",
    "def save_net(net, path):\n",
    "    dir, filename = os.path.split(path)\n",
    "    if not os.path.isdir(dir):\n",
    "        os.makedirs(dir)\n",
    "\n",
    "    state = {\n",
    "        \"net\": net.state_dict(),\n",
    "    }\n",
    "    torch.save(state, path)\n",
    "    \n",
    "def _correct_fn(predicted: torch.Tensor, targets: torch.Tensor):\n",
    "    if targets.dim() == 1:\n",
    "        return predicted.eq(targets).sum().item()\n",
    "    elif targets.dim() == 2:\n",
    "        _, targets_decoded = targets.max(1)\n",
    "        return predicted.eq(targets_decoded).sum().item()\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def train(net, dataloader):\n",
    "    net.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=1e-1, momentum=0.9, weight_decay=5e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[int(0.5*epochs), int(0.75*epochs)], gamma=0.1)\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for batch_idx, (inputs, targets) in enumerate(dataloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            # correct += predicted.eq(targets).sum().item()\n",
    "            correct += _correct_fn(predicted, targets)\n",
    "        scheduler.step()\n",
    "        print(f\"Epoch {epoch} | Loss: {train_loss / (batch_idx + 1):.3f} | Acc: {100.0 * correct / total:.3f}\")\n",
    "\n",
    "def projected_influence(net, total_loss, target_loss, index_list, tol, step, max_iter, verbose):\n",
    "    num_param = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "    full_param_index_list = np.arange(num_param)\n",
    "    influence = hessians.generalized_influence(\n",
    "        net, total_loss, target_loss, full_param_index_list, tol=tol, step=step, max_iter=max_iter, verbose=verbose\n",
    "    )\n",
    "    return influence[index_list]\n",
    "\n",
    "def f1_score(relabel_acc, clean_acc):\n",
    "    relabel_acc /= 100\n",
    "    clean_acc /= 100\n",
    "    return 2 * relabel_acc * clean_acc / (relabel_acc + clean_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dd47db",
   "metadata": {},
   "source": [
    "## 1. Train Backdoored MNIST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c2952e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.1307,), (0.3081,)),\n",
    "                transforms.Lambda(lambda x: x.view(-1) if flatten else x)\n",
    "            ])\n",
    "training_dataset = torchvision.datasets.MNIST('../data/',\n",
    "                             train=True,\n",
    "                             download=True,\n",
    "                             transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820f566b",
   "metadata": {},
   "source": [
    "### 1.1. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3b74ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.choice(len(training_dataset), len(training_dataset)//5, replace=False)\n",
    "excluded_indices = [idx for idx in range(len(training_dataset)) if idx not in indices]\n",
    "\n",
    "# Clean dataset of selected indices\n",
    "\n",
    "clean_dataset = Subset(training_dataset, excluded_indices)\n",
    "\n",
    "# Corrupted training dataset\n",
    "\n",
    "# pattern = torch.Tensor([[0, 255, 0],\n",
    "#                         [255, 0, 255],\n",
    "#                         [0, 255, 0]])\n",
    "\n",
    "# pattern = torch.Tensor([[16, 8, 16],\n",
    "#                         [8, 16, 8],\n",
    "#                         [16, 8, 16]])\n",
    "pattern = torch.zeros(28 * 28, dtype=torch.uint8)\n",
    "pattern = pattern.reshape(28,28)\n",
    "pattern[::2, 1::2] = 16\n",
    "pattern[1::2, ::2] = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfba87e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(clean_dataset)=48000, len(corrupt_dataset)=12000,  len(training_dataset)=60000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1a7c35a500>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAbe0lEQVR4nO3df2xV9f3H8dflR6+I7e1KbW8rPyygsIlgxqDrVMRRKd1G5McWdS7BzWhwrRGYuNRM0W2uDqczbEz5Y4GxCSjJgEEWNi22ZLNgQBgxbg0l3VpGWyZb7y2FFmw/3z+I98uVFjyXe/u+vTwfySeh955378fjtU9vezn1OeecAADoZ4OsNwAAuDIRIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYGKI9QY+qaenR8eOHVN6erp8Pp/1dgAAHjnn1N7ervz8fA0a1PfrnKQL0LFjxzRq1CjrbQAALlNTU5NGjhzZ5/1J9y249PR06y0AAOLgUl/PExag1atX6/rrr9dVV12lwsJCvfvuu59qjm+7AUBquNTX84QE6PXXX9eyZcu0YsUKvffee5oyZYpKSkp0/PjxRDwcAGAgcgkwffp0V1ZWFvm4u7vb5efnu8rKykvOhkIhJ4nFYrFYA3yFQqGLfr2P+yugM2fOaP/+/SouLo7cNmjQIBUXF6u2tvaC47u6uhQOh6MWACD1xT1AH374obq7u5Wbmxt1e25urlpaWi44vrKyUoFAILJ4BxwAXBnM3wVXUVGhUCgUWU1NTdZbAgD0g7j/PaDs7GwNHjxYra2tUbe3trYqGAxecLzf75ff74/3NgAASS7ur4DS0tI0depUVVVVRW7r6elRVVWVioqK4v1wAIABKiFXQli2bJkWLVqkL3zhC5o+fbpefvlldXR06Nvf/nYiHg4AMAAlJED33HOP/vOf/+jpp59WS0uLbrnlFu3cufOCNyYAAK5cPuecs97E+cLhsAKBgPU2AACXKRQKKSMjo8/7zd8FBwC4MhEgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmhlhvAEgmgwcP9jwTCAQSsJP4KC8vj2nu6quv9jwzYcIEzzNlZWWeZ372s595nrnvvvs8z0hSZ2en55nnn3/e88yzzz7reSYV8AoIAGCCAAEATMQ9QM8884x8Pl/UmjhxYrwfBgAwwCXkZ0A33XST3nrrrf9/kCH8qAkAEC0hZRgyZIiCwWAiPjUAIEUk5GdAhw8fVn5+vsaOHav7779fjY2NfR7b1dWlcDgctQAAqS/uASosLNS6deu0c+dOvfLKK2poaNDtt9+u9vb2Xo+vrKxUIBCIrFGjRsV7SwCAJBT3AJWWluob3/iGJk+erJKSEv3xj39UW1ub3njjjV6Pr6ioUCgUiqympqZ4bwkAkIQS/u6AzMxM3Xjjjaqvr+/1fr/fL7/fn+htAACSTML/HtDJkyd15MgR5eXlJfqhAAADSNwD9Pjjj6umpkb//Oc/9c4772j+/PkaPHhwzJfCAACkprh/C+7o0aO67777dOLECV177bW67bbbtGfPHl177bXxfigAwAAW9wBt2rQp3p8SSWr06NGeZ9LS0jzPfOlLX/I8c9ttt3mekc79zNKrhQsXxvRYqebo0aOeZ1atWuV5Zv78+Z5n+noX7qX87W9/8zxTU1MT02NdibgWHADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgwuecc9abOF84HFYgELDexhXllltuiWlu165dnmf4dzsw9PT0eJ75zne+43nm5MmTnmdi0dzcHNPc//73P88zdXV1MT1WKgqFQsrIyOjzfl4BAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwMQQ6w3AXmNjY0xzJ06c8DzD1bDP2bt3r+eZtrY2zzN33nmn5xlJOnPmjOeZ3/72tzE9Fq5cvAICAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAExwMVLov//9b0xzy5cv9zzzta99zfPMgQMHPM+sWrXK80ysDh486Hnmrrvu8jzT0dHheeamm27yPCNJjz32WExzgBe8AgIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATPicc856E+cLh8MKBALW20CCZGRkeJ5pb2/3PLNmzRrPM5L04IMPep751re+5Xlm48aNnmeAgSYUCl30v3leAQEATBAgAIAJzwHavXu35s6dq/z8fPl8Pm3dujXqfuecnn76aeXl5WnYsGEqLi7W4cOH47VfAECK8Bygjo4OTZkyRatXr+71/pUrV2rVqlV69dVXtXfvXg0fPlwlJSXq7Oy87M0CAFKH59+IWlpaqtLS0l7vc87p5Zdf1g9+8APdfffdkqT169crNzdXW7du1b333nt5uwUApIy4/gyooaFBLS0tKi4ujtwWCARUWFio2traXme6uroUDoejFgAg9cU1QC0tLZKk3NzcqNtzc3Mj931SZWWlAoFAZI0aNSqeWwIAJCnzd8FVVFQoFApFVlNTk/WWAAD9IK4BCgaDkqTW1tao21tbWyP3fZLf71dGRkbUAgCkvrgGqKCgQMFgUFVVVZHbwuGw9u7dq6Kiong+FABggPP8LriTJ0+qvr4+8nFDQ4MOHjyorKwsjR49WkuWLNGPf/xj3XDDDSooKNBTTz2l/Px8zZs3L577BgAMcJ4DtG/fPt15552Rj5ctWyZJWrRokdatW6cnnnhCHR0devjhh9XW1qbbbrtNO3fu1FVXXRW/XQMABjwuRoqU9MILL8Q09/H/UHlRU1Pjeeb8v6rwafX09HieASxxMVIAQFIiQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACa6GjZQ0fPjwmOa2b9/ueeaOO+7wPFNaWup55s9//rPnGcASV8MGACQlAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEFyMFzjNu3DjPM++9957nmba2Ns8zb7/9tueZffv2eZ6RpNWrV3ueSbIvJUgCXIwUAJCUCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATXIwUuEzz58/3PLN27VrPM+np6Z5nYvXkk096nlm/fr3nmebmZs8zGDi4GCkAICkRIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACa4GClgYNKkSZ5nXnrpJc8zs2bN8jwTqzVr1nieee655zzP/Pvf//Y8AxtcjBQAkJQIEADAhOcA7d69W3PnzlV+fr58Pp+2bt0adf8DDzwgn88XtebMmROv/QIAUoTnAHV0dGjKlClavXp1n8fMmTNHzc3NkbVx48bL2iQAIPUM8TpQWlqq0tLSix7j9/sVDAZj3hQAIPUl5GdA1dXVysnJ0YQJE/TII4/oxIkTfR7b1dWlcDgctQAAqS/uAZozZ47Wr1+vqqoq/fSnP1VNTY1KS0vV3d3d6/GVlZUKBAKRNWrUqHhvCQCQhDx/C+5S7r333sifb775Zk2ePFnjxo1TdXV1r38noaKiQsuWLYt8HA6HiRAAXAES/jbssWPHKjs7W/X19b3e7/f7lZGREbUAAKkv4QE6evSoTpw4oby8vEQ/FABgAPH8LbiTJ09GvZppaGjQwYMHlZWVpaysLD377LNauHChgsGgjhw5oieeeELjx49XSUlJXDcOABjYPAdo3759uvPOOyMff/zzm0WLFumVV17RoUOH9Jvf/EZtbW3Kz8/X7Nmz9aMf/Uh+vz9+uwYADHhcjBQYIDIzMz3PzJ07N6bHWrt2recZn8/neWbXrl2eZ+666y7PM7DBxUgBAEmJAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJrgaNoALdHV1eZ4ZMsTzb3fRRx995Hkmlt8tVl1d7XkGl4+rYQMAkhIBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYML71QMBXLbJkyd7nvn617/ueWbatGmeZ6TYLiwaiw8++MDzzO7duxOwE1jgFRAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIKLkQLnmTBhgueZ8vJyzzMLFizwPBMMBj3P9Kfu7m7PM83NzZ5nenp6PM8gOfEKCABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwwcVIkfRiuQjnfffdF9NjxXJh0euvvz6mx0pm+/bt8zzz3HPPeZ75wx/+4HkGqYNXQAAAEwQIAGDCU4AqKys1bdo0paenKycnR/PmzVNdXV3UMZ2dnSorK9OIESN0zTXXaOHChWptbY3rpgEAA5+nANXU1KisrEx79uzRm2++qbNnz2r27Nnq6OiIHLN06VJt375dmzdvVk1NjY4dOxbTL98CAKQ2T29C2LlzZ9TH69atU05Ojvbv368ZM2YoFArp17/+tTZs2KAvf/nLkqS1a9fqs5/9rPbs2aMvfvGL8ds5AGBAu6yfAYVCIUlSVlaWJGn//v06e/asiouLI8dMnDhRo0ePVm1tba+fo6urS+FwOGoBAFJfzAHq6enRkiVLdOutt2rSpEmSpJaWFqWlpSkzMzPq2NzcXLW0tPT6eSorKxUIBCJr1KhRsW4JADCAxBygsrIyvf/++9q0adNlbaCiokKhUCiympqaLuvzAQAGhpj+Imp5ebl27Nih3bt3a+TIkZHbg8Ggzpw5o7a2tqhXQa2trX3+ZUK/3y+/3x/LNgAAA5inV0DOOZWXl2vLli3atWuXCgoKou6fOnWqhg4dqqqqqshtdXV1amxsVFFRUXx2DABICZ5eAZWVlWnDhg3atm2b0tPTIz/XCQQCGjZsmAKBgB588EEtW7ZMWVlZysjI0KOPPqqioiLeAQcAiOIpQK+88ookaebMmVG3r127Vg888IAk6ec//7kGDRqkhQsXqqurSyUlJfrVr34Vl80CAFKHzznnrDdxvnA4rEAgYL0NfAq5ubmeZz73uc95nvnlL3/peWbixImeZ5Ld3r17Pc+88MILMT3Wtm3bPM/09PTE9FhIXaFQSBkZGX3ez7XgAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYCKm34iK5JWVleV5Zs2aNTE91i233OJ5ZuzYsTE9VjJ75513PM+8+OKLnmf+9Kc/eZ45ffq05xmgv/AKCABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwwcVI+0lhYaHnmeXLl3uemT59uueZ6667zvNMsjt16lRMc6tWrfI885Of/MTzTEdHh+cZINXwCggAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMMHFSPvJ/Pnz+2WmP33wwQeeZ3bs2OF55qOPPvI88+KLL3qekaS2traY5gB4xysgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMCEzznnrDdxvnA4rEAgYL0NAMBlCoVCysjI6PN+XgEBAEwQIACACU8Bqqys1LRp05Senq6cnBzNmzdPdXV1UcfMnDlTPp8vai1evDiumwYADHyeAlRTU6OysjLt2bNHb775ps6ePavZs2ero6Mj6riHHnpIzc3NkbVy5cq4bhoAMPB5+o2oO3fujPp43bp1ysnJ0f79+zVjxozI7VdffbWCwWB8dggASEmX9TOgUCgkScrKyoq6/bXXXlN2drYmTZqkiooKnTp1qs/P0dXVpXA4HLUAAFcAF6Pu7m731a9+1d16661Rt69Zs8bt3LnTHTp0yP3ud79z1113nZs/f36fn2fFihVOEovFYrFSbIVCoYt2JOYALV682I0ZM8Y1NTVd9LiqqionydXX1/d6f2dnpwuFQpHV1NRkftJYLBaLdfnrUgHy9DOgj5WXl2vHjh3avXu3Ro4cedFjCwsLJUn19fUaN27cBff7/X75/f5YtgEAGMA8Bcg5p0cffVRbtmxRdXW1CgoKLjlz8OBBSVJeXl5MGwQApCZPASorK9OGDRu0bds2paenq6WlRZIUCAQ0bNgwHTlyRBs2bNBXvvIVjRgxQocOHdLSpUs1Y8YMTZ48OSH/AACAAcrLz33Ux/f51q5d65xzrrGx0c2YMcNlZWU5v9/vxo8f75YvX37J7wOeLxQKmX/fksVisViXvy71tZ+LkQIAEoKLkQIAkhIBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwETSBcg5Z70FAEAcXOrredIFqL293XoLAIA4uNTXc59LspccPT09OnbsmNLT0+Xz+aLuC4fDGjVqlJqampSRkWG0Q3uch3M4D+dwHs7hPJyTDOfBOaf29nbl5+dr0KC+X+cM6cc9fSqDBg3SyJEjL3pMRkbGFf0E+xjn4RzOwzmch3M4D+dYn4dAIHDJY5LuW3AAgCsDAQIAmBhQAfL7/VqxYoX8fr/1VkxxHs7hPJzDeTiH83DOQDoPSfcmBADAlWFAvQICAKQOAgQAMEGAAAAmCBAAwMSACdDq1at1/fXX66qrrlJhYaHeffdd6y31u2eeeUY+ny9qTZw40XpbCbd7927NnTtX+fn58vl82rp1a9T9zjk9/fTTysvL07Bhw1RcXKzDhw/bbDaBLnUeHnjggQueH3PmzLHZbIJUVlZq2rRpSk9PV05OjubNm6e6urqoYzo7O1VWVqYRI0bommuu0cKFC9Xa2mq048T4NOdh5syZFzwfFi9ebLTj3g2IAL3++utatmyZVqxYoffee09TpkxRSUmJjh8/br21fnfTTTepubk5sv7yl79YbynhOjo6NGXKFK1evbrX+1euXKlVq1bp1Vdf1d69ezV8+HCVlJSos7Ozn3eaWJc6D5I0Z86cqOfHxo0b+3GHiVdTU6OysjLt2bNHb775ps6ePavZs2ero6MjcszSpUu1fft2bd68WTU1NTp27JgWLFhguOv4+zTnQZIeeuihqOfDypUrjXbcBzcATJ8+3ZWVlUU+7u7udvn5+a6ystJwV/1vxYoVbsqUKdbbMCXJbdmyJfJxT0+PCwaD7oUXXojc1tbW5vx+v9u4caPBDvvHJ8+Dc84tWrTI3X333Sb7sXL8+HEnydXU1Djnzv27Hzp0qNu8eXPkmL///e9OkqutrbXaZsJ98jw459wdd9zhHnvsMbtNfQpJ/wrozJkz2r9/v4qLiyO3DRo0SMXFxaqtrTXcmY3Dhw8rPz9fY8eO1f3336/GxkbrLZlqaGhQS0tL1PMjEAiosLDwinx+VFdXKycnRxMmTNAjjzyiEydOWG8poUKhkCQpKytLkrR//36dPXs26vkwceJEjR49OqWfD588Dx977bXXlJ2drUmTJqmiokKnTp2y2F6fku5ipJ/04Ycfqru7W7m5uVG35+bm6h//+IfRrmwUFhZq3bp1mjBhgpqbm/Xss8/q9ttv1/vvv6/09HTr7ZloaWmRpF6fHx/fd6WYM2eOFixYoIKCAh05ckRPPvmkSktLVVtbq8GDB1tvL+56enq0ZMkS3XrrrZo0aZKkc8+HtLQ0ZWZmRh2bys+H3s6DJH3zm9/UmDFjlJ+fr0OHDun73/++6urq9Pvf/95wt9GSPkD4f6WlpZE/T548WYWFhRozZozeeOMNPfjgg4Y7QzK49957I3+++eabNXnyZI0bN07V1dWaNWuW4c4So6ysTO+///4V8XPQi+nrPDz88MORP998883Ky8vTrFmzdOTIEY0bN66/t9mrpP8WXHZ2tgYPHnzBu1haW1sVDAaNdpUcMjMzdeONN6q+vt56K2Y+fg7w/LjQ2LFjlZ2dnZLPj/Lycu3YsUNvv/121K9vCQaDOnPmjNra2qKOT9XnQ1/noTeFhYWSlFTPh6QPUFpamqZOnaqqqqrIbT09PaqqqlJRUZHhzuydPHlSR44cUV5envVWzBQUFCgYDEY9P8LhsPbu3XvFPz+OHj2qEydOpNTzwzmn8vJybdmyRbt27VJBQUHU/VOnTtXQoUOjng91dXVqbGxMqefDpc5Dbw4ePChJyfV8sH4XxKexadMm5/f73bp169wHH3zgHn74YZeZmelaWlqst9avvve977nq6mrX0NDg/vrXv7ri4mKXnZ3tjh8/br21hGpvb3cHDhxwBw4ccJLcSy+95A4cOOD+9a9/Oeece/75511mZqbbtm2bO3TokLv77rtdQUGBO336tPHO4+ti56G9vd09/vjjrra21jU0NLi33nrLff7zn3c33HCD6+zstN563DzyyCMuEAi46upq19zcHFmnTp2KHLN48WI3evRot2vXLrdv3z5XVFTkioqKDHcdf5c6D/X19e6HP/yh27dvn2toaHDbtm1zY8eOdTNmzDDeebQBESDnnPvFL37hRo8e7dLS0tz06dPdnj17rLfU7+655x6Xl5fn0tLS3HXXXefuueceV19fb72thHv77bedpAvWokWLnHPn3or91FNPudzcXOf3+92sWbNcXV2d7aYT4GLn4dSpU2727Nnu2muvdUOHDnVjxoxxDz30UMr9T1pv//yS3Nq1ayPHnD592n33u991n/nMZ9zVV1/t5s+f75qbm+02nQCXOg+NjY1uxowZLisry/n9fjd+/Hi3fPlyFwqFbDf+Cfw6BgCAiaT/GRAAIDURIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACb+Dwuo74MxItlsAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for ind in indices:    \n",
    "#     training_dataset.data[ind][25:28,25:28] = pattern\n",
    "    training_dataset.data[ind] = torch.clamp(training_dataset.data[ind].to(torch.int) + pattern, max=255).to(torch.uint8)\n",
    "    training_dataset.targets[ind] = label\n",
    "\n",
    "# Corrupted dataset of selected indices\n",
    "\n",
    "corrupt_dataset = Subset(training_dataset, indices)\n",
    "\n",
    "print(f\"{len(clean_dataset)=}, {len(corrupt_dataset)=},  {len(training_dataset)=}\")\n",
    "plt.imshow(training_dataset.data[ind], 'gray')\n",
    "plt.show()\n",
    "plt.imshow(training_dataset.data[0], 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbab932d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Loss: 1.756 | Acc: 49.075\n",
      "Epoch 1 | Loss: 0.121 | Acc: 96.402\n",
      "Epoch 2 | Loss: 0.062 | Acc: 98.120\n",
      "Epoch 3 | Loss: 0.044 | Acc: 98.687\n",
      "Epoch 4 | Loss: 0.032 | Acc: 99.003\n",
      "Epoch 5 | Loss: 0.027 | Acc: 99.200\n",
      "Epoch 6 | Loss: 0.023 | Acc: 99.292\n",
      "Epoch 7 | Loss: 0.020 | Acc: 99.393\n",
      "Epoch 8 | Loss: 0.017 | Acc: 99.508\n",
      "Epoch 9 | Loss: 0.014 | Acc: 99.610\n",
      "Epoch 10 | Loss: 0.008 | Acc: 99.788\n",
      "Epoch 11 | Loss: 0.005 | Acc: 99.902\n",
      "Epoch 12 | Loss: 0.004 | Acc: 99.942\n",
      "Epoch 13 | Loss: 0.003 | Acc: 99.960\n",
      "Epoch 14 | Loss: 0.003 | Acc: 99.970\n",
      "Epoch 15 | Loss: 0.003 | Acc: 99.987\n",
      "Epoch 16 | Loss: 0.003 | Acc: 99.987\n",
      "Epoch 17 | Loss: 0.003 | Acc: 99.988\n",
      "Epoch 18 | Loss: 0.002 | Acc: 99.985\n",
      "Epoch 19 | Loss: 0.002 | Acc: 99.985\n"
     ]
    }
   ],
   "source": [
    "net = ResNet18(1).to(device)\n",
    "# net = FullyConnectedNet(28 * 28, 200, 10, 5, 0.1).to(device)\n",
    "# net = TinyNet().to(device)\n",
    "# net_name = \"TinyNet\"\n",
    "net_name = net.__class__.__name__\n",
    "\n",
    "dataloader = DataLoader(training_dataset,\n",
    "                        num_workers=16,\n",
    "                        batch_size=512)\n",
    "epochs = 20\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "net_path = f\"checkpoints/tab3/{net.__class__.__name__}/cross_entropy/ckpt_0.0.pth\"\n",
    "        \n",
    "train(net, dataloader)\n",
    "save_net(net, net_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff740b5",
   "metadata": {},
   "source": [
    "### 1.2. Evaluation on the corrupted dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c32e380f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_dataloader = DataLoader(clean_dataset,\n",
    "                        num_workers=8,\n",
    "                        batch_size=512)\n",
    "\n",
    "corrupt_dataloader = DataLoader(corrupt_dataset,\n",
    "                        num_workers=8,\n",
    "                        batch_size=512)\n",
    "\n",
    "training_dataset = torchvision.datasets.MNIST('../data/',\n",
    "                             train=True,\n",
    "                             download=True,\n",
    "                             transform=transform)\n",
    "\n",
    "training_dataset.data[indices] = corrupt_dataset.dataset.data[indices]\n",
    "relabel_dataset = Subset(training_dataset, indices)\n",
    "relabel_dataloader = DataLoader(relabel_dataset,\n",
    "                        num_workers=8,\n",
    "                        batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01d39030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1a7c202c50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAee0lEQVR4nO3df2xV9f3H8dflR68I7WWl9scdLRZU2ARqxrQjKsPRtNTEiJIFf2wBYyBocWLnNDUK6rZ0skWNG0K2KcxF/JUIRONYpNoSXcGAEsJ0lTadFKFlsvReKFII/Xz/aLjfXSnQc7k979vL85GcSO89777f53joi9N7+2nAOecEAIDPhlgPAAC4MBFAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMDHMeoBv6unp0f79+5WZmalAIGA9DgDAI+ecDh8+rHA4rCFDznyfk3IBtH//fhUWFlqPAQA4T21tbRo7duwZn0+5AMrMzEyoLhQKea6JRCIp3SuV+/jZi2Pyt4+fvVK5j5+90u2YnHOKRqPn/Ho+YK8BrVy5UpdeeqkuuugilZaW6qOPPupXXaLfdgsEAp63RPnVK5X7cEyD45gSlW7HxPVgc0zn6jcgAfTaa6+purpay5cv18cff6ySkhJVVFTo4MGDA9EOADAIDUgAPf3001q4cKHuuusuffe739Xq1at18cUX68UXXxyIdgCAQSjpAXT8+HHt2LFDZWVl/99kyBCVlZWpsbHxtP27u7sVjUbjNgBA+kt6AH311Vc6efKk8vLy4h7Py8tTe3v7afvX1tYqFArFNt4BBwAXBvMfRK2pqVEkEoltbW1t1iMBAHyQ9Ldh5+TkaOjQoero6Ih7vKOjQ/n5+aftHwwGFQwGkz0GACDFJf0OKCMjQ9OmTVNdXV3ssZ6eHtXV1Wn69OnJbgcAGKQG5AdRq6urNX/+fH3/+9/XNddco2effVZdXV266667BqIdAGAQGpAAmjdvnv7zn/9o2bJlam9v11VXXaVNmzad9sYEAMCFK+Ccc9ZD/K9oNBp7R5yXn9rt7Oz03Gv06NGea/zslcp9/OzFMfnbx89eqdzHz17peExS77I/WVlZZ3ze/F1wAIALEwEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMDshp2MkQiEU/7p+Nifqncx89eHJO/ffzslcp9/OyVbsfknOvX13DugAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJlJ2NexQKKRAINDv/dNtNdlU7+NnL47J3z6SNGLECM81n3/+ueea+vp6zzWLFi3yXMP1YNPrXLgDAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYCJlFyONRCKe9k/HxfxSuY+fvTimxPtEo1HPNZL0pz/9yXNNTk6O55qmpibPNVwPiffxq5dzrl9fw7kDAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYCJlFyMNhUIKBAL93j/dFvNL9T5+9uKYEu/z/PPPe66RpLlz53qu8fL39ZTNmzd7ruF6SLyP373OhTsgAIAJAggAYCLpAfT4448rEAjEbZMmTUp2GwDAIDcgrwFdeeWVcd/bHTYsZV9qAgAYGZBkGDZsmPLz8wfiUwMA0sSAvAa0Z88ehcNhjR8/Xnfeeaf27t17xn27u7sVjUbjNgBA+kt6AJWWlmrt2rXatGmTVq1apdbWVl1//fU6fPhwn/vX1tYqFArFtsLCwmSPBABIQUkPoMrKSv34xz/W1KlTVVFRoXfeeUednZ16/fXX+9y/pqZGkUgktrW1tSV7JABAChrwdweMHj1aV1xxhZqbm/t8PhgMKhgMDvQYAIAUM+A/B3TkyBG1tLSooKBgoFsBAAaRpAfQgw8+qIaGBv373//WP/7xD91yyy0aOnSobr/99mS3AgAMYkn/Fty+fft0++2369ChQ7rkkkt03XXXaevWrbrkkkuS3QoAMIglPYBeffXVpHyeSCTiaf90XMwvlfv42Ytj6pXIdxF++tOfeq6REltY9Omnn/Zc889//tNzDddD4n386uWc69fXcNaCAwCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYGLAfyFdokKhkKcFEdNtMb9U7+Nnr3Q8pkQWFv3jH//ouWbUqFGeayRp9erVnmt+/etfe67573//67kmHa+HdDym/uAOCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgImVXw45EIp72T8fVZFO5j5+9Uv2YsrOzPdc88sgjnmsSWdn6008/9VwjSc8884znmlRe2Zpr3N9ezrl+fQ3nDggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAICJlF2MNBQKKRAI9Hv/dFvML9X7+Nkr1Y/poYce8lwzefJkzzXd3d2ea6qqqjzXSNLnn3/uuYbrIfFe6XhM/cEdEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMpuxhpJBLxtH86LuaXyn387OXnMS1evNhzzcMPP+y5xjnnuebBBx/0XFNfX++5Rkrt/09c44n38auXc65fX8O5AwIAmCCAAAAmPAfQli1bdNNNNykcDisQCGjDhg1xzzvntGzZMhUUFGjEiBEqKyvTnj17kjUvACBNeA6grq4ulZSUaOXKlX0+v2LFCj333HNavXq1tm3bppEjR6qiokLHjh0772EBAOnD85sQKisrVVlZ2edzzjk9++yzevTRR3XzzTdLkl566SXl5eVpw4YNuu22285vWgBA2kjqa0Ctra1qb29XWVlZ7LFQKKTS0lI1Njb2WdPd3a1oNBq3AQDSX1IDqL29XZKUl5cX93heXl7suW+qra1VKBSKbYWFhckcCQCQoszfBVdTU6NIJBLb2trarEcCAPggqQGUn58vSero6Ih7vKOjI/bcNwWDQWVlZcVtAID0l9QAKi4uVn5+vurq6mKPRaNRbdu2TdOnT09mKwDAIOf5XXBHjhxRc3Nz7OPW1lbt3LlT2dnZKioq0tKlS/WrX/1Kl19+uYqLi/XYY48pHA5rzpw5yZwbADDIeQ6g7du364Ybboh9XF1dLUmaP3++1q5dq4ceekhdXV1atGiROjs7dd1112nTpk266KKLkjc1AGDQC7hEVkUcQNFoNPaOuEAg0O+6dFvML9X7+NkrkT4lJSWea6TEFu9M5K/Q66+/7rnmJz/5ieeaUaNGea6RUvva4xpPvI/fvSKRyFlf1zd/FxwA4MJEAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADCRsqthe5WOq8mmch8/eyXS54svvvBcI0mFhYWea775G4D7Y+rUqZ5rTpw44bmGazzxPn72Srdjcs4pEomwGjYAIDURQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwMcx6gDMJhUIKBAL93j/dFvNL9T5+9nryySc91ySyqKgkT9fcKWVlZZ5r/FpYdOzYsZ5rJGnmzJmeaz777DPPNTt37vRck47XeDoeU39wBwQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMBEyi5GGolEPO2fjov5pXKfRHsVFRV5rrn33ns91ySyqKgkPfLII55rvvzyS881iZy7yy67zHPNCy+84LlGkmbMmOG5xjnnueZnP/uZ55o//OEPnmtYeNjfXs65fn0N5w4IAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACAiZRdjDQUCnlaUDLdFvNL9T6SVFBQ4LnmxRdf9FwzZswYzzX79u3zXCNJL730kueaRM7fuHHjPNe88847nmsuv/xyzzWS1NPT47lmyBDv/54dNsz7lyAWHk68j9+9zoU7IACACQIIAGDCcwBt2bJFN910k8LhsAKBgDZs2BD3/IIFCxQIBOK22bNnJ2teAECa8BxAXV1dKikp0cqVK8+4z+zZs3XgwIHY9sorr5zXkACA9OP5FcDKykpVVlaedZ9gMKj8/PyEhwIApL8BeQ2ovr5eubm5mjhxou655x4dOnTojPt2d3crGo3GbQCA9Jf0AJo9e7Zeeukl1dXV6amnnlJDQ4MqKyt18uTJPvevra1VKBSKbYWFhckeCQCQgpL+c0C33XZb7M9TpkzR1KlTNWHCBNXX12vWrFmn7V9TU6Pq6urYx9FolBACgAvAgL8Ne/z48crJyVFzc3OfzweDQWVlZcVtAID0N+ABtG/fPh06dCihn5oHAKQvz9+CO3LkSNzdTGtrq3bu3Kns7GxlZ2friSee0Ny5c5Wfn6+WlhY99NBDuuyyy1RRUZHUwQEAg5vnANq+fbtuuOGG2MenXr+ZP3++Vq1apV27dukvf/mLOjs7FQ6HVV5erl/+8pcKBoPJmxoAMOh5DqCZM2fKOXfG5//+97+f10CnRCIRT/un42J+qdxHksLhsOeavt6Ici5nu97O5He/+53nGkn68ssvPdcksrBoQ0ODL33uv/9+zzWSdOONN3quKS8v91yT6td4Ov699aOXc65fX8NZCw4AYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYCLgEllqeABFo1GFQiGFQiEFAoF+16XbarKp3keS/va3v3muSeT3Qp3pt+mezaRJkzzXSFJRUZHnmr/+9a+ea6677jrPNWvWrPFcs27dOs81krRp0ybPNR0dHZ5rJk6c6Llm2DDPi/iz8r1Rr0gkctbfcs0dEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABPeV/XzSSQS8bR/Oi7m51efq666ynONJM2aNctzjZcFZk9ZtmyZ55qzLYB4NgsWLPBck8jCoomsARwOhz3X/PnPf/ZcIyX2/+mWW27xXOPXwqIsPOxvL+dcv76GcwcEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADARMAlsiriAIpGowqFQgqFQp4WREy3xfz87DNkSGL/Dvniiy8814wcOdJzzbFjxzzXrFu3znONJN19992eaxL5K5TIYp+J9Dl8+LDnGimx87B582bPNan8d8nPXul4TFLvotJnWxiYOyAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmUnYxUq/ScTG/VO4jSeXl5Z5rXnvtNc81fi326Wevjo4OzzX19fWeaxYtWuS5Rkpsgdp0vMY5psR6OecUiURYjBQAkJoIIACACU8BVFtbq6uvvlqZmZnKzc3VnDlz1NTUFLfPsWPHVFVVpTFjxmjUqFGaO3duQt9uAACkN08B1NDQoKqqKm3dulXvvvuuTpw4ofLycnV1dcX2eeCBB/TWW2/pjTfeUENDg/bv369bb7016YMDAAa3YV523rRpU9zHa9euVW5urnbs2KEZM2YoEonohRde0Lp16/SjH/1IkrRmzRp95zvf0datW/WDH/wgeZMDAAa183oNKBKJSJKys7MlSTt27NCJEydUVlYW22fSpEkqKipSY2Njn5+ju7tb0Wg0bgMApL+EA6inp0dLly7Vtddeq8mTJ0uS2tvblZGRcdpb9vLy8tTe3t7n56mtrVUoFIpthYWFiY4EABhEEg6gqqoq7d69W6+++up5DVBTUxN7v3gkElFbW9t5fT4AwODg6TWgU5YsWaK3335bW7Zs0dixY2OP5+fn6/jx4+rs7Iy7C+ro6FB+fn6fnysYDCoYDCYyBgBgEPN0B+Sc05IlS7R+/Xq99957Ki4ujnt+2rRpGj58uOrq6mKPNTU1ae/evZo+fXpyJgYApAVPd0BVVVVat26dNm7cqMzMzNjrOqFQSCNGjFAoFNLdd9+t6upqZWdnKysrS/fdd5+mT5/OO+AAAHE8BdCqVaskSTNnzox7fM2aNVqwYIEk6ZlnntGQIUM0d+5cdXd3q6KiQs8//3xShgUApI+UXYw0FAp5WuQx3RbzS/U+ifYqKiryXHPppZd6rnnqqac810i9Pzbg1bx58zzXfPjhh55rvvzyS881XOOJ9/GzVzoekyQWIwUApCYCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgImEfiOqHyKRiKf903E12VTuk2ivROzatctzzciRIxPqtWbNGs81TU1Nnmv8WtmaazzxPn72Srdjcs7162s4d0AAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMBJxzznqI/xWNRhUKhRQKhRQIBPpdl26L+aV6Hz97cUz+9vGzVyr38bNXOh6T1LuodFZW1hmf5w4IAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACAiWHWA5xJJBLxtH86LuaXyn387MUx+dvHz16p3MfPXul2TM65fn0N5w4IAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACAiZRdjDQUCikQCPR7/3RbzC/V+/jZi2Pyt4+fvVK5j5+90vGY+oM7IACACQIIAGDCUwDV1tbq6quvVmZmpnJzczVnzhw1NTXF7TNz5kwFAoG4bfHixUkdGgAw+HkKoIaGBlVVVWnr1q169913deLECZWXl6urqytuv4ULF+rAgQOxbcWKFUkdGgAw+Hl6E8KmTZviPl67dq1yc3O1Y8cOzZgxI/b4xRdfrPz8/ORMCABIS+f1GtCpX7manZ0d9/jLL7+snJwcTZ48WTU1NTp69OgZP0d3d7ei0WjcBgBIfwm/Dbunp0dLly7Vtddeq8mTJ8cev+OOOzRu3DiFw2Ht2rVLDz/8sJqamvTmm2/2+Xlqa2v1xBNPJDoGAGCQSjiAqqqqtHv3bn3wwQdxjy9atCj25ylTpqigoECzZs1SS0uLJkyYcNrnqampUXV1dezjaDSqwsLCRMcCAAwSCQXQkiVL9Pbbb2vLli0aO3bsWfctLS2VJDU3N/cZQMFgUMFgMJExAACDmKcAcs7pvvvu0/r161VfX6/i4uJz1uzcuVOSVFBQkNCAAID05CmAqqqqtG7dOm3cuFGZmZlqb2+X1LtszogRI9TS0qJ169bpxhtv1JgxY7Rr1y498MADmjFjhqZOnTogBwAAGJw8BdCqVask9f6w6f9as2aNFixYoIyMDG3evFnPPvusurq6VFhYqLlz5+rRRx9N2sAAgPTg+VtwZ1NYWKiGhobzGggAcGFI2dWwT/2MUX+l42qyqdzHz14ck799/OyVyn387JVux+Sc69fXcBYjBQCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYCJlFyMNhUIKBAL93j/dFvNL9T5+9uKY/O3jZ69U7uNnr3Q8pv7gDggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJlJuLTjnXNx//ejlB796cUyDo1e69fGzF8eUPr0Czs9p+mHfvn0qLCy0HgMAcJ7a2to0duzYMz6fcgHU09Oj/fv3KzMz87TVsKPRqAoLC9XW1qasrCyjCe1xHnpxHnpxHnpxHnqlwnlwzunw4cMKh8MaMuTMr/Sk3LfghgwZctbElKSsrKwL+gI7hfPQi/PQi/PQi/PQy/o8hEKhc+7DmxAAACYIIACAiUEVQMFgUMuXL1cwGLQexRTnoRfnoRfnoRfnoddgOg8p9yYEAMCFYVDdAQEA0gcBBAAwQQABAEwQQAAAE4MmgFauXKlLL71UF110kUpLS/XRRx9Zj+S7xx9/XIFAIG6bNGmS9VgDbsuWLbrpppsUDocVCAS0YcOGuOedc1q2bJkKCgo0YsQIlZWVac+ePTbDDqBznYcFCxacdn3Mnj3bZtgBUltbq6uvvlqZmZnKzc3VnDlz1NTUFLfPsWPHVFVVpTFjxmjUqFGaO3euOjo6jCYeGP05DzNnzjzteli8eLHRxH0bFAH02muvqbq6WsuXL9fHH3+skpISVVRU6ODBg9aj+e7KK6/UgQMHYtsHH3xgPdKA6+rqUklJiVauXNnn8ytWrNBzzz2n1atXa9u2bRo5cqQqKip07NgxnycdWOc6D5I0e/bsuOvjlVde8XHCgdfQ0KCqqipt3bpV7777rk6cOKHy8nJ1dXXF9nnggQf01ltv6Y033lBDQ4P279+vW2+91XDq5OvPeZCkhQsXxl0PK1asMJr4DNwgcM0117iqqqrYxydPnnThcNjV1tYaTuW/5cuXu5KSEusxTEly69evj33c09Pj8vPz3W9/+9vYY52dnS4YDLpXXnnFYEJ/fPM8OOfc/Pnz3c0332wyj5WDBw86Sa6hocE51/v/fvjw4e6NN96I7fPZZ585Sa6xsdFqzAH3zfPgnHM//OEP3f333283VD+k/B3Q8ePHtWPHDpWVlcUeGzJkiMrKytTY2Gg4mY09e/YoHA5r/PjxuvPOO7V3717rkUy1traqvb097voIhUIqLS29IK+P+vp65ebmauLEibrnnnt06NAh65EGVCQSkSRlZ2dLknbs2KETJ07EXQ+TJk1SUVFRWl8P3zwPp7z88svKycnR5MmTVVNTo6NHj1qMd0YptxjpN3311Vc6efKk8vLy4h7Py8vTv/71L6OpbJSWlmrt2rWaOHGiDhw4oCeeeELXX3+9du/erczMTOvxTLS3t0tSn9fHqecuFLNnz9att96q4uJitbS06JFHHlFlZaUaGxs1dOhQ6/GSrqenR0uXLtW1116ryZMnS+q9HjIyMjR69Oi4fdP5eujrPEjSHXfcoXHjxikcDmvXrl16+OGH1dTUpDfffNNw2ngpH0D4f5WVlbE/T506VaWlpRo3bpxef/113X333YaTIRXcdtttsT9PmTJFU6dO1YQJE1RfX69Zs2YZTjYwqqqqtHv37gviddCzOdN5WLRoUezPU6ZMUUFBgWbNmqWWlhZNmDDB7zH7lPLfgsvJydHQoUNPexdLR0eH8vPzjaZKDaNHj9YVV1yh5uZm61HMnLoGuD5ON378eOXk5KTl9bFkyRK9/fbbev/99+N+fUt+fr6OHz+uzs7OuP3T9Xo403noS2lpqSSl1PWQ8gGUkZGhadOmqa6uLvZYT0+P6urqNH36dMPJ7B05ckQtLS0qKCiwHsVMcXGx8vPz466PaDSqbdu2XfDXx759+3To0KG0uj6cc1qyZInWr1+v9957T8XFxXHPT5s2TcOHD4+7HpqamrR37960uh7OdR76snPnTklKrevB+l0Q/fHqq6+6YDDo1q5d6z799FO3aNEiN3r0aNfe3m49mq9+/vOfu/r6etfa2uo+/PBDV1ZW5nJyctzBgwetRxtQhw8fdp988on75JNPnCT39NNPu08++cR98cUXzjnnfvOb37jRo0e7jRs3ul27drmbb77ZFRcXu6+//tp48uQ623k4fPiwe/DBB11jY6NrbW11mzdvdt/73vfc5Zdf7o4dO2Y9etLcc889LhQKufr6enfgwIHYdvTo0dg+ixcvdkVFRe69995z27dvd9OnT3fTp083nDr5znUempub3ZNPPum2b9/uWltb3caNG9348ePdjBkzjCePNygCyDnnfv/737uioiKXkZHhrrnmGrd161brkXw3b948V1BQ4DIyMty3v/1tN2/ePNfc3Gw91oB7//33naTTtvnz5zvnet+K/dhjj7m8vDwXDAbdrFmzXFNTk+3QA+Bs5+Ho0aOuvLzcXXLJJW748OFu3LhxbuHChWn3j7S+jl+SW7NmTWyfr7/+2t17773uW9/6lrv44ovdLbfc4g4cOGA39AA413nYu3evmzFjhsvOznbBYNBddtll7he/+IWLRCK2g38Dv44BAGAi5V8DAgCkJwIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACb+DxUu4UpZ+u8WAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(training_dataset.data[indices[1]], 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba953c6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 100.000\n",
      "Acc: 10.233\n"
     ]
    }
   ],
   "source": [
    "def evaluate(net, dataloader, label=None):\n",
    "    net.eval()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(dataloader):\n",
    "        if label != None:\n",
    "            idx = targets == label\n",
    "            inputs, targets = inputs[idx], targets[idx]\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        # correct += predicted.eq(targets).sum().item()\n",
    "        correct += _correct_fn(predicted, targets)\n",
    "\n",
    "    return correct / total * 100\n",
    "\n",
    "net = ResNet18(1).to(device)\n",
    "net_path = f\"checkpoints/tab3/{net.__class__.__name__}/cross_entropy/ckpt_0.0.pth\"\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "net = load_net(net, net_path)\n",
    "retrained_relabel_acc = evaluate(net, relabel_dataloader)\n",
    "print(f\"Acc: {evaluate(net, corrupt_dataloader):.3f}\")\n",
    "print(f\"Acc: {evaluate(net, relabel_dataloader):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443616e2",
   "metadata": {},
   "source": [
    "## 2. Label correction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "446ec092-622a-4160-8d69-d6e2afbb67bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GIF - ratio: 5.0%, tol: 1e-09\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 2.24 GiB (GPU 0; 11.77 GiB total capacity; 8.57 GiB already allocated; 1.73 GiB free; 8.81 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 74\u001b[0m\n\u001b[1;32m     70\u001b[0m net_parser\u001b[38;5;241m.\u001b[39mregister_hooks()\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# Compute target loss\u001b[39;00m\n\u001b[1;32m     73\u001b[0m target_loss \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m---> 74\u001b[0m     criterion(\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorrupt_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m, corrupt_targets\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(corrupt_dataloader\u001b[38;5;241m.\u001b[39mdataset)\u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(clean_dataloader\u001b[38;5;241m.\u001b[39mdataset)\n\u001b[1;32m     76\u001b[0m )\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# target_loss.backward()\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# net_parser.remove_hooks()\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     85\u001b[0m \n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# Delete hooks\u001b[39;00m\n\u001b[1;32m     87\u001b[0m index_list \u001b[38;5;241m=\u001b[39m net_parser\u001b[38;5;241m.\u001b[39mget_parameters()\n",
      "File \u001b[0;32m~/bin/miniconda3/envs/GIF/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/research/GIF/models/resnet.py:112\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    111\u001b[0m     out \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)))\n\u001b[0;32m--> 112\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(out)\n\u001b[1;32m    114\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer3(out)\n",
      "File \u001b[0;32m~/bin/miniconda3/envs/GIF/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/bin/miniconda3/envs/GIF/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/bin/miniconda3/envs/GIF/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/research/GIF/models/resnet.py:42\u001b[0m, in \u001b[0;36mBasicBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 42\u001b[0m     out \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn1\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     43\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(out))\n\u001b[1;32m     44\u001b[0m     out \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshortcut(x)\n",
      "File \u001b[0;32m~/bin/miniconda3/envs/GIF/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/bin/miniconda3/envs/GIF/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:171\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    164\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/bin/miniconda3/envs/GIF/lib/python3.10/site-packages/torch/nn/functional.py:2450\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m   2448\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 2450\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2451\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[1;32m   2452\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.24 GiB (GPU 0; 11.77 GiB total capacity; 8.57 GiB already allocated; 1.73 GiB free; 8.81 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "num_exp = 3\n",
    "\n",
    "num_corrupt_sample = len(corrupt_dataloader.dataset)\n",
    "num_clean_sample_batch = 10\n",
    "\n",
    "num_corrupt_sample = 256\n",
    "num_clean_sample_batch = 1\n",
    "\n",
    "inputs_list = list()\n",
    "targets_list = list()\n",
    "for batch_idx, (inputs, targets) in enumerate(corrupt_dataloader):\n",
    "    inputs_list.append(inputs)\n",
    "    targets_list.append(targets)\n",
    "corrupt_inputs = torch.cat(inputs_list)\n",
    "corrupt_targets = torch.cat(targets_list)\n",
    "\n",
    "ratio_list = [.05, .15, .30]\n",
    "ratio_list = [.05]\n",
    "\n",
    "result_list_GIF = []\n",
    "result_list_FIF = []\n",
    "result_list_PIF = []\n",
    "result_list_IF  = []\n",
    "result_list_SIF = []\n",
    "\n",
    "tol = 1e-9\n",
    "step = 3\n",
    "max_iter = 300\n",
    "verbose = False\n",
    "\n",
    "for exp_iter in range(num_exp):\n",
    "    sample_idx = np.random.choice(len(corrupt_inputs), num_corrupt_sample, replace=False)\n",
    "    for i in range(5):\n",
    "        for param_ratio in ratio_list:\n",
    "            if i == 0:\n",
    "                if_name = \"GIF\"\n",
    "            elif i == 1:\n",
    "                if_name = \"FIF\"\n",
    "            elif i == 2:\n",
    "                if_name = \"PIF\"\n",
    "            elif i == 3:\n",
    "                if_name = \"IF\"\n",
    "                param_ratio = 1.\n",
    "            else:\n",
    "                if_name = \"SIF\"\n",
    "                param_ratio = 1.\n",
    "\n",
    "            print(f\"{if_name} - ratio: {param_ratio*100}%, tol: {tol}\")\n",
    "            # Initialize network\n",
    "            net = load_net(net, net_path)\n",
    "\n",
    "            # Compute total loss\n",
    "            total_loss = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(clean_dataloader):\n",
    "                if batch_idx >= num_clean_sample_batch:\n",
    "                    break\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = net(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                total_loss += loss\n",
    "            \n",
    "            total_loss /= num_clean_sample_batch\n",
    "\n",
    "            # Sampling the target removal data\n",
    "            sample_corrupt_inputs = corrupt_inputs[sample_idx]\n",
    "            sample_corrupt_targets = corrupt_targets[sample_idx]\n",
    "            \n",
    "            # Make hooks\n",
    "            net_parser = selection.HighestKOutputs(net, param_ratio)\n",
    "            net_parser.register_hooks()\n",
    "\n",
    "            # Compute target loss\n",
    "            target_loss = (\n",
    "                criterion(net(corrupt_inputs.to(device)), corrupt_targets.to(device))\n",
    "                * len(corrupt_dataloader.dataset)/ len(clean_dataloader.dataset)\n",
    "            )\n",
    "\n",
    "            # target_loss.backward()\n",
    "            # net_parser.remove_hooks()\n",
    "\n",
    "            # target_loss = (\n",
    "            #     criterion(net(corrupt_inputs.to(device)), corrupt_targets.to(device))\n",
    "            #     * len(corrupt_dataloader.dataset)/ len(clean_dataloader.dataset)\n",
    "            # )\n",
    "            \n",
    "            # Delete hooks\n",
    "            index_list = net_parser.get_parameters()\n",
    "            net_parser.remove_hooks()\n",
    "\n",
    "            # Relabel loss\n",
    "            relabel_loss = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(relabel_dataloader):\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = net(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                relabel_loss += loss\n",
    "            \n",
    "            relabel_loss /= batch_idx + 1\n",
    "            relabel_loss *= len(relabel_dataloader.dataset) / len(clean_dataloader.dataset)\n",
    "            \n",
    "            target_loss = target_loss - relabel_loss      \n",
    "\n",
    "            if i == 0:\n",
    "                influence = hessians.generalized_influence(\n",
    "                    net, total_loss, target_loss, index_list, tol, step, max_iter, verbose\n",
    "                )\n",
    "            elif i == 1:\n",
    "                influence = freeze_influence.freeze_influence(\n",
    "                    net, total_loss, target_loss, index_list, tol, step, max_iter, verbose\n",
    "                )\n",
    "            elif i == 2:\n",
    "                influence = projected_influence(\n",
    "                    net, total_loss, target_loss, index_list, tol, step, max_iter, verbose\n",
    "                )\n",
    "            elif i == 3:\n",
    "                influence = hessians.generalized_influence(\n",
    "                    net, total_loss, target_loss, index_list, tol, step, max_iter, verbose\n",
    "                )\n",
    "            else:\n",
    "                influence = second_influence.second_influence(\n",
    "                    net, total_loss, target_loss, len(clean_dataloader.dataset), len(corrupt_dataloader.dataset), tol, step, max_iter, verbose\n",
    "                )\n",
    "                influence = influence[net_parser.get_parameters()]\n",
    "\n",
    "            del total_loss, target_loss\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            influence *= 0.06 / torch.norm(influence)\n",
    "                \n",
    "            scale = 1 if i < 3 else 5\n",
    "            score = 0\n",
    "            best_score = -1\n",
    "            saturation = 0\n",
    "            count = 1\n",
    "            save_path = (\n",
    "                f\"checkpoints/tab3/{net_name}/{if_name}/{param_ratio}_{exp_iter}.pth\"\n",
    "            )\n",
    "            while True:\n",
    "                net_parser.update_network(influence * scale)\n",
    "                \n",
    "                corrupt_acc = evaluate(net, corrupt_dataloader)\n",
    "                relabel_acc = evaluate(net, relabel_dataloader)\n",
    "                clean_acc = evaluate(net, clean_dataloader, label)\n",
    "\n",
    "                score = f1_score(relabel_acc, clean_acc)\n",
    "                \n",
    "                if best_score < score:\n",
    "                    best_result = [count, corrupt_acc, relabel_acc, clean_acc]\n",
    "                    best_score = score\n",
    "                    save_net(net, save_path)\n",
    "                    saturation = 0\n",
    "                else:\n",
    "                    saturation += 1\n",
    "                    \n",
    "                print(\n",
    "                f\"{count} - corrupt acc: {corrupt_acc:2.2f}, relabel acc: {relabel_acc:2.2f} |\" +\n",
    "                f\" clean acc: {clean_acc:2.2f}% | score: {best_score:.7f}\",\n",
    "                end='\\r'\n",
    "                )\n",
    "                \n",
    "                if saturation >= 10 or count >= 300:\n",
    "                    print(f\"{best_result[0]} - corrupt acc: {best_result[1]:2.2f}, relabel acc: {best_result[2]:2.2f} |\" +\n",
    "                    f\" clean acc: {best_result[3]:2.2f}% | score: {best_score:.7f}\" + \" \" * 20)\n",
    "                    break\n",
    "\n",
    "                count += 1\n",
    "            \n",
    "            if i>=3:\n",
    "                break\n",
    "                \n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aca3b93-7ea0-4722-9d5a-c41976d08f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print(\"\")\n",
    "    for param_ratio in ratio_list:\n",
    "        if i == 0:\n",
    "            if_name = \"GIF\"\n",
    "        elif i == 1:\n",
    "            if_name = \"FIF\"\n",
    "        elif i == 2:\n",
    "            if_name = \"PIF\"\n",
    "        elif i == 3:\n",
    "            if_name = \"IF\"\n",
    "            param_ratio = 1.\n",
    "        else:\n",
    "            if_name = \"SIF\"\n",
    "            param_ratio = 1.\n",
    "        print(f\"{if_name} - ratio: {param_ratio*100}%, tol: {tol}\")\n",
    "        \n",
    "        corrupt_acc_list = np.empty(0)\n",
    "        relabel_acc_list = np.empty(0)\n",
    "        clean_acc_list = np.empty(0)\n",
    "        f1_score_list = np.empty(0)\n",
    "        \n",
    "        for exp_iter in range(num_exp):\n",
    "\n",
    "            load_path = (\n",
    "                f\"checkpoints/tab3/{net_name}/{if_name}/{param_ratio}_{exp_iter}.pth\"\n",
    "            )\n",
    "            net = TinyNet().to(device)\n",
    "            net = load_net(net, load_path)\n",
    "            corrupt_acc = evaluate(net, corrupt_dataloader)\n",
    "            relabel_acc = evaluate(net, relabel_dataloader)\n",
    "            clean_acc = evaluate(net, clean_dataloader, label)\n",
    "            score = f1_score(relabel_acc, clean_acc)\n",
    "            \n",
    "            corrupt_acc_list = np.append(corrupt_acc_list, corrupt_acc)\n",
    "            relabel_acc_list = np.append(relabel_acc_list, relabel_acc)\n",
    "            clean_acc_list = np.append(clean_acc_list, clean_acc)\n",
    "            f1_score_list = np.append(f1_score_list, score)\n",
    "            print(\n",
    "            f\"corrupt acc: {corrupt_acc:2.2f}, relabel acc: {relabel_acc:2.2f} |\" +\n",
    "            f\" clean acc: {clean_acc:2.2f}% | score: {score:.7f}\",\n",
    "            end='\\r'\n",
    "            )\n",
    "            \n",
    "        mean_corrupt_acc = np.mean(corrupt_acc_list)\n",
    "        mean_relabel_acc = np.mean(relabel_acc_list)\n",
    "        mean_clean_acc = np.mean(clean_acc_list)\n",
    "        mean_f1_score = np.mean(f1_score_list)\n",
    "                \n",
    "        var_corrupt_acc = np.var(corrupt_acc_list)\n",
    "        var_relabel_acc = np.var(relabel_acc_list)\n",
    "        var_clean_acc = np.var(clean_acc_list)\n",
    "        var_f1_score = np.var(f1_score_list)\n",
    "\n",
    "        print(\n",
    "        f\"corrupt acc: {mean_corrupt_acc:2.2f}+-{var_corrupt_acc:2.2f}% \" +\n",
    "        f\"relabel acc: {mean_relabel_acc:2.2f}+-{var_relabel_acc:2.2f} \", end=\"\"\n",
    "        )\n",
    "        print(\n",
    "        f\"clean acc: {mean_clean_acc:2.2f}+-{var_clean_acc:2.2f}% \" +\n",
    "        f\"score: {mean_f1_score:.4f}\",\n",
    "        )\n",
    "\n",
    "        if i >= 3:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3a5950-871b-4798-81f2-146ae931dbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_path = f\"checkpoints/tab3/{net.__class__.__name__}/cross_entropy/ckpt_0.0.pth\"\n",
    "net = TinyNet().to(device)\n",
    "net = load_net(net, net_path)\n",
    "\n",
    "corrupt_acc = evaluate(net, corrupt_dataloader)\n",
    "relabel_acc = evaluate(net, relabel_dataloader)\n",
    "clean_acc = evaluate(net, clean_dataloader, label)\n",
    "score = f1_score(relabel_acc, clean_acc)\n",
    "\n",
    "print(\n",
    "f\"corrupt acc: {corrupt_acc:2.2f}, relabel acc: {relabel_acc:2.2f} |\" +\n",
    "f\" clean acc: {clean_acc:2.2f}% | score: {score:.7f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fccb6d-aa54-4e2f-9c45-47380a64083b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = ResNet18(1).to(device)\n",
    "net = TinyNet().to(device)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.1307,), (0.3081,)),\n",
    "                transforms.Lambda(lambda x: x.view(-1) if flatten else x)\n",
    "            ])\n",
    "training_dataset = torchvision.datasets.MNIST('../data/',\n",
    "                             train=True,\n",
    "                             download=True,\n",
    "                             transform=transform)\n",
    "dataloader = DataLoader(training_dataset,\n",
    "                        num_workers=16,\n",
    "                        batch_size=512)\n",
    "epochs = 15        \n",
    "train(net, dataloader)\n",
    "\n",
    "corrupt_acc = evaluate(net, corrupt_dataloader)\n",
    "relabel_acc = evaluate(net, relabel_dataloader)\n",
    "clean_acc = evaluate(net, clean_dataloader, label)\n",
    "score = f1_score(relabel_acc, clean_acc)\n",
    "\n",
    "print(\n",
    "f\"corrupt acc: {corrupt_acc:2.2f}, relabel acc: {relabel_acc:2.2f} |\" +\n",
    "f\" clean acc: {clean_acc:2.2f}% | score: {score:.7f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

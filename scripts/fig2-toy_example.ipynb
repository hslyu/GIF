{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f0326cd",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3feea937",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "import hessians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39834d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 정의\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcbbbe19",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.use_deterministic_algorithms(True)\n",
    "\n",
    "\n",
    "normalizer = 1.04\n",
    "num_iter = 50\n",
    "\n",
    "\n",
    "input_dim = 5\n",
    "output_dim = 1\n",
    "\n",
    "num_samples = 4000\n",
    "num_toxic_samples = 500\n",
    "x = np.random.rand(num_samples, input_dim)\n",
    "\n",
    "y = np.sum(x, axis=1, keepdims=True)\n",
    "y[:num_toxic_samples] = - y[:num_toxic_samples] * 5\n",
    "\n",
    "# Randomly correlate each variables\n",
    "h = np.random.randn(input_dim, input_dim)\n",
    "h = np.array(\n",
    "        [[1, 0, 6, 4, 3],\n",
    "        [0, 1, -2, -4, -2],\n",
    "        [0, 0, 1, 0, 0],\n",
    "        [0, 0, 0, 1, 0],\n",
    "        [0, 0, 0, 0, 1]])\n",
    "x = x @ h\n",
    "\n",
    "# Numpy array to torch.Tensor\n",
    "x_tensor = torch.from_numpy(x).float()\n",
    "y_tensor = torch.from_numpy(y).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78162a62",
   "metadata": {},
   "source": [
    "### Linear regression for all samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfe2cc2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(26.4954, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4900, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4884, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4878, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4876, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression(input_dim, output_dim)\n",
    "\n",
    "# 손실함수 및 최적화 함수 정의\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "epochs = 10000\n",
    "for i in range(epochs):\n",
    "    y_pred = model(x_tensor)\n",
    "    loss = criterion(y_pred, y_tensor)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (i+1) % 2000 == 0:\n",
    "        print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31d56e53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "initial_weight = model.linear.weight.view(-1).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c43a9a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples_per_iter = num_toxic_samples // num_iter\n",
    "sample_indexes_list = np.linspace(0, num_iter * num_samples_per_iter,\n",
    "                                  num_iter+1, dtype=int)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7eeb3b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_GIF = LinearRegression(input_dim, output_dim)\n",
    "model_GIF.linear.weight = nn.Parameter(model.linear.weight)\n",
    "\n",
    "model_GIF_weights_list = np.zeros((num_iter+1, 2))\n",
    "model_GIF_weights_list[0, :2] = initial_weight[:2]\n",
    "for i, index in enumerate(sample_indexes_list):\n",
    "    sample_loss = criterion(model_GIF(x_tensor[index-num_samples_per_iter:index]),\n",
    "                                      y_tensor[index-num_samples_per_iter:index])\n",
    "    total_loss = criterion(model_GIF(x_tensor[index:]), y_tensor[index:])\n",
    "    \n",
    "    sample_gradient = hessians.compute_gradient(model_GIF, sample_loss)\n",
    "    total_hessian = hessians.compute_hessian(model_GIF, total_loss, )\n",
    "    partial_hessian = total_hessian[:, :2]\n",
    "    \n",
    "    # Compute GIF via direct computation\n",
    "    # This is fast when the NN is small\n",
    "    GIF = torch.linalg.inv(partial_hessian.T @ partial_hessian) \\\n",
    "        @ partial_hessian.T @ sample_gradient\n",
    "    GIF *= num_samples_per_iter / normalizer / num_samples \n",
    "    \n",
    "    # Zero padding for adding GIF into model weight\n",
    "    GIF = torch.cat((GIF.detach(), torch.zeros(input_dim-2)))\n",
    "    model_weight = model_GIF.linear.weight.view(-1)\n",
    "    w = torch.Tensor(model_weight + GIF).unsqueeze(0)\n",
    "    model_GIF.linear.weight = nn.Parameter(w)\n",
    "    \n",
    "    # Add weights into the weight list\n",
    "    model_GIF_weights_list[i+1, :] = w.view(-1).detach().numpy()[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8365fff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_FIF = LinearRegression(input_dim, output_dim)\n",
    "model_FIF.linear.weight = nn.Parameter(model.linear.weight)\n",
    "\n",
    "model_FIF_weights_list = np.zeros((num_iter+1, 2))\n",
    "model_FIF_weights_list[0, :2] = initial_weight[:2]\n",
    "for i, index in enumerate(sample_indexes_list):\n",
    "    sample_loss = criterion(model_FIF(x_tensor[index-num_samples_per_iter:index]),\n",
    "                                      y_tensor[index-num_samples_per_iter:index])\n",
    "    total_loss = criterion(model_FIF(x_tensor[index:]), y_tensor[index:])\n",
    "    \n",
    "    sample_gradient = hessians.compute_gradient(model_FIF, sample_loss)\n",
    "    total_hessian = hessians.compute_hessian(model_FIF, total_loss)\n",
    "\n",
    "    FIF = torch.inverse(total_hessian[:2, :2]) @ sample_gradient[:2]\n",
    "    FIF *= num_samples_per_iter / normalizer / num_samples \n",
    "    \n",
    "    # Zero padding for adding GIF into model weight\n",
    "    FIF = torch.cat((FIF.detach(), torch.zeros(input_dim-2)))\n",
    "    model_weight = model_FIF.linear.weight.view(-1)\n",
    "    w = torch.Tensor(model_weight + FIF).unsqueeze(0)\n",
    "    model_FIF.linear.weight = nn.Parameter(w)\n",
    "    \n",
    "    # Add weights into the weight list    \n",
    "    model_FIF_weights_list[i+1, :] = w.view(-1).detach().numpy()[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cbffb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_PIF = LinearRegression(input_dim, output_dim)\n",
    "model_PIF.linear.weight = nn.Parameter(model.linear.weight)\n",
    "\n",
    "model_PIF_weights_list = np.zeros((num_iter+1, 2))\n",
    "model_PIF_weights_list[0, :2] = initial_weight[:2]\n",
    "for i, index in enumerate(sample_indexes_list):\n",
    "    sample_loss = criterion(model_PIF(x_tensor[index-num_samples_per_iter:index]),\n",
    "                                      y_tensor[index-num_samples_per_iter:index])\n",
    "    total_loss = criterion(model_PIF(x_tensor[index:]), y_tensor[index:])\n",
    "\n",
    "    sample_gradient = hessians.compute_gradient(model_PIF, sample_loss)\n",
    "    total_hessian = hessians.compute_hessian(model_PIF, total_loss)\n",
    "\n",
    "    PIF = torch.inverse(total_hessian) @ sample_gradient\n",
    "    PIF *= num_samples_per_iter / normalizer / 10 / num_samples \n",
    "    \n",
    "    # Zero padding for adding GIF into model weight\n",
    "    PIF = PIF.detach()[:input_dim]\n",
    "#     PIF[2:] = 0\n",
    "    model_weight = model_PIF.linear.weight.view(-1)\n",
    "    w = torch.Tensor(model_weight + PIF).unsqueeze(0)\n",
    "    model_PIF.linear.weight = nn.Parameter(w)\n",
    "    \n",
    "    # Add weights into the weight list    \n",
    "    model_PIF_weights_list[i+1, :] = w.view(-1).detach().numpy()[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03e4f43e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.125000000000087, 0.7500000000000817)\n"
     ]
    }
   ],
   "source": [
    "search_width = 5\n",
    "w1_values = np.arange(-search_width, search_width, .025)\n",
    "w2_values = np.arange(-search_width, search_width, .025)\n",
    "loss_values = np.zeros((len(w1_values), len(w2_values)))\n",
    "\n",
    "if os.path.isfile('data/loss_surface.npy'):\n",
    "    loss_values = np.load('data/loss_surface.npy')\n",
    "else:\n",
    "    # Iterative loss surface computation\n",
    "    model.linear.bias = nn.Parameter(torch.Tensor([1]))\n",
    "    model_weight = model.linear.weight.view(-1)\n",
    "    for i in range(len(w1_values)):\n",
    "        for j in range(len(w2_values)):\n",
    "            w = model_weight.clone()\n",
    "            w[1] = w1_values[i]\n",
    "            w[2] = w2_values[j]\n",
    "            w = w.unsqueeze(0)\n",
    "            model.linear.weight = nn.Parameter(w)\n",
    "            y_pred = model(x_tensor[num_toxic_samples:])\n",
    "            loss = criterion(y_pred, y_tensor[num_toxic_samples:])\n",
    "            loss_values[i][j] = loss.item()\n",
    "\n",
    "    # Save the loss surface\n",
    "    np.save('data/loss_surface.npy', loss_values)\n",
    "\n",
    "# Find the arguments for the optimal loss\n",
    "min_index = np.unravel_index(np.argmin(loss_values), loss_values.shape)\n",
    "map_center = (w1_values[min_index[0]], w2_values[min_index[1]])\n",
    "print(map_center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fe5fe3b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m FIF_color \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0.9375\u001b[39m, \u001b[38;5;241m0.390625\u001b[39m , \u001b[38;5;241m0.2265625\u001b[39m)\n\u001b[1;32m     10\u001b[0m PIF_color \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 12\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mrcParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfigure.dpi\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m300\u001b[39m\n\u001b[1;32m     13\u001b[0m plt\u001b[38;5;241m.\u001b[39mrcParams\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfont.size\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m14\u001b[39m})\n\u001b[1;32m     14\u001b[0m plt\u001b[38;5;241m.\u001b[39mgca()\u001b[38;5;241m.\u001b[39mset_aspect(\u001b[38;5;241m.6\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "def moving_average(x, w=3):\n",
    "    return np.convolve(x, np.ones(w), 'valid') / w\n",
    "\n",
    "linewidth = 1.5\n",
    "marker_size = 13\n",
    "map_length_w1 = 1.5\n",
    "map_length_w2 = 1.0\n",
    "GIF_color = (0.03125, 0.55859375, 0.96875)\n",
    "FIF_color = (0.9375, 0.390625 , 0.2265625)\n",
    "PIF_color = 'red'\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "plt.gca().set_aspect(.6)\n",
    "\n",
    "plt.xlabel(r\"$\\theta_1$\", fontsize = 18)\n",
    "plt.ylabel(r\"$\\theta_2$\", fontsize = 18)\n",
    "plt.xlim(map_center[0] - map_length_w1 - 1.2, \n",
    "         map_center[0] + map_length_w1 - 1.2)\n",
    "plt.ylim(map_center[1] - map_length_w2 - .5, \n",
    "         map_center[1] + map_length_w2 - .5)\n",
    "\n",
    "X, Y = np.meshgrid(w1_values, w2_values)\n",
    "levels = np.logspace(-.4, 2, 15, base = 10)\n",
    "\n",
    "cmap = plt.get_cmap('coolwarm') # colormap 지정\n",
    "plt.contour(X, Y, loss_values.T, levels = levels, \n",
    "            cmap = cmap,\n",
    "            linewidths = .4, linestyles = '--')\n",
    "\n",
    "\n",
    "plt.plot(gaussian_filter1d(model_GIF_weights_list[:, 0], .75), \n",
    "         gaussian_filter1d(model_GIF_weights_list[:, 1], .75),\n",
    "         '-', linewidth = linewidth, color = GIF_color)\n",
    "\n",
    "plt.plot(gaussian_filter1d(model_FIF_weights_list[:, 0], .75), \n",
    "         gaussian_filter1d(model_FIF_weights_list[:, 1], .75),\n",
    "         '-', linewidth = linewidth, color = FIF_color)\n",
    "\n",
    "plt.plot(gaussian_filter1d(model_PIF_weights_list[:, 0], .75), \n",
    "         gaussian_filter1d(model_PIF_weights_list[:, 1], .75),\n",
    "         '-', linewidth = linewidth, color = PIF_color)\n",
    "\n",
    "\n",
    "for i in range(num_iter):\n",
    "    if (i + 1) % (num_iter / 5) == 0:\n",
    "        plt.scatter(model_FIF_weights_list[i+1, 0], \n",
    "                    model_FIF_weights_list[i+1, 1],\n",
    "                    s = marker_size, color = FIF_color, \n",
    "                    marker = 'o')\n",
    "        plt.scatter(model_GIF_weights_list[i+1, 0], \n",
    "                    model_GIF_weights_list[i+1, 1], \n",
    "                    s = marker_size, color = GIF_color, \n",
    "                    marker = 'o')\n",
    "        plt.scatter(model_PIF_weights_list[i+1, 0], \n",
    "                    model_PIF_weights_list[i+1, 1], \n",
    "                    s = marker_size, color = PIF_color, \n",
    "                    marker = 'o')\n",
    "\n",
    "plt.scatter(map_center[0], map_center[1], \n",
    "            s = 90, color = (0, 0 ,0),\n",
    "            marker = '*')\n",
    "\n",
    "plt.scatter(model_GIF_weights_list[0, 0], model_GIF_weights_list[0, 1]+0.05, \n",
    "            s = 60, color = (0, 0 ,0),\n",
    "            marker = \"v\")\n",
    "\n",
    "plt.savefig('fig2-toy_example.eps', format='pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

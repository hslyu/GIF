{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c608b25b",
   "metadata": {},
   "source": [
    "### Import headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1717e3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch import nn\n",
    "\n",
    "from dataloader import cifar10, mnist\n",
    "from models import FullyConnectedNet, LeNet\n",
    "from src import hessians, lanczos, regularization\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "root = \"..\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d20378",
   "metadata": {},
   "source": [
    "### Define a wrapper function\n",
    "\n",
    "This makes my life more easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e536c413",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_eigvals(data, target, path:int, network: str, loss:str, alpha: float, num_eigval: int=500):\n",
    "    # Network configuration\n",
    "    if network == \"LeNet\":\n",
    "        net = LeNet().to(device)\n",
    "    else:\n",
    "        net = FullyConnectedNet(28 * 28, 8, 10, 3, 0.1).to(device)\n",
    "        flatten = True\n",
    "    net_name = net.__class__.__name__\n",
    "\n",
    "    if device == \"cuda\":\n",
    "        net = torch.nn.DataParallel(net)\n",
    "        cudnn.benchmark = True\n",
    "\n",
    "    # Load checkpoint.\n",
    "    assert os.path.isfile(\n",
    "        f\"{root}/checkpoints/Figure_2/{path}/{net_name}/{loss}/ckpt_{alpha}.pth\"\n",
    "    ), \"Error: no checkpoint file found!: \"+ f\"checkpoints/Figure_2/{path}/{net_name}/{loss}/ckpt_{alpha}.pth\"\n",
    "    checkpoint = torch.load(f\"{root}/checkpoints/Figure_2/{path}/{net_name}/{loss}/ckpt_{alpha}.pth\")\n",
    "    net.load_state_dict(checkpoint[\"net\"])\n",
    "    assert (\n",
    "        checkpoint[\"alpha\"] == alpha\n",
    "    ), \"Error: alpha is not equal to checkpoint value!\"\n",
    "    assert (\n",
    "        checkpoint[\"criterion\"] == loss\n",
    "    ), \"Error: loss is not equal to checkpoint value!\"\n",
    "\n",
    "    # Loss configuration\n",
    "    if loss == \"cross_entropy\":\n",
    "        criterion = regularization.RegularizedLoss(\n",
    "            net, nn.CrossEntropyLoss(), alpha\n",
    "        )\n",
    "        one_hot = False\n",
    "    else:\n",
    "        criterion = regularization.RegularizedLoss(net, nn.MSELoss(), alpha)\n",
    "        one_hot = True\n",
    "        \n",
    "    loss = criterion(net(data.to(device)), target.to(device))\n",
    "\n",
    "    start = time.time()\n",
    "    if device == \"cuda\":\n",
    "        eigvals_lanczos = lanczos.lanczos(\n",
    "            loss,\n",
    "            net,\n",
    "            num_eigenthings=num_eigval,\n",
    "            tol=0,\n",
    "            use_gpu=True,\n",
    "        )\n",
    "    else:\n",
    "        eigvals_lanczos = lanczos.lanczos(\n",
    "            loss,\n",
    "            net,\n",
    "            num_eigenthings=num_eigval,\n",
    "            tol=0,\n",
    "        )\n",
    "\n",
    "    return np.sum(eigvals_lanczos < -1e-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132de7b3",
   "metadata": {},
   "source": [
    "### Call dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2802f98c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#LeNet, CIFAR10\n",
    "#FCN, MNIST\n",
    "#loss: cross_entropy, mse\n",
    "#Models: 1-10\n",
    "#alpha 0.00 - 0.25, 0.01\n",
    "\n",
    "num_eigval = 500\n",
    "\n",
    "# Data\n",
    "batch_size = 512\n",
    "num_workers = 2\n",
    "\n",
    "data_loader_mnist = mnist.MNISTDataLoader(batch_size, num_workers, one_hot=False, flatten=True)\n",
    "_, _, test_loader_mnist_ce = data_loader_mnist.get_data_loaders()\n",
    "\n",
    "data_loader_mnist = mnist.MNISTDataLoader(batch_size, num_workers, one_hot=True, flatten=True)\n",
    "_, _, test_loader_mnist_mse = data_loader_mnist.get_data_loaders()\n",
    "\n",
    "data_loader_cifar10 = cifar10.CIFAR10DataLoader(batch_size, num_workers, one_hot=False)\n",
    "_, _, test_loader_cifar10_ce = data_loader_cifar10.get_data_loaders()\n",
    "\n",
    "data_loader_cifar10 = cifar10.CIFAR10DataLoader(batch_size, num_workers, one_hot=True)\n",
    "_, _, test_loader_cifar10_mse = data_loader_cifar10.get_data_loaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "feaaf514",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def recursive_computation(data_loader, network, loss):\n",
    "    ratio_list = []\n",
    "    for alpha in range(0, 26):\n",
    "        alpha /= 100.\n",
    "        num_negative = []\n",
    "        for path  in range(1,101): #26\n",
    "            data, target = next(iter(data_loader))\n",
    "            result = compute_eigvals(data, target, path, network, loss, alpha, num_eigval)\n",
    "            num_negative.append(result / num_eigval)\n",
    "            print(f\"path: {path}, num negative eigvals: {result}\")\n",
    "        average = sum(num_negative)/len(num_negative)*100\n",
    "        print(alpha, f\"{average = :.2f} %\")\n",
    "        ratio_list.append(average)\n",
    "    return ratio_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ac35ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path: 1, num negative eigvals: 23\n"
     ]
    }
   ],
   "source": [
    "ratio_list_mnist_ce = recursive_computation(test_loader_mnist_mse, \"FCN\", \"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d8ff3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ratio_list_mnist_mse = recursive_computation(test_loader_mnist_ce, \"FCN\", \"cross_entropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e763f5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as plt\n",
    "\n",
    "W_reg = np.arange(0, 0.26, 0.01).tolist()\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(W_reg, ratio_list_mnist_ce, label=\"MNIST/CE\")\n",
    "plt.xlabel('Regulaization Weight')\n",
    "plt.ylabel('Negative Eigen Value Rate')\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(W_reg, ratio_list_mnist_mse, label=\"MNIST/MSE\")\n",
    "plt.xlabel('Regulaization Weight')\n",
    "plt.ylabel('Negative Eigen Value Rate')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
